{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19c74892",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "from IPython.display import Audio  #播放套件\n",
    "import matplotlib.pyplot as plt \n",
    "import librosa.display  #libroso 繪圖\n",
    "import time\n",
    "import os, re\n",
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84e8de9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.06738126e-02, 3.03121395e-02, 2.54061874e-02, ...,\n",
       "        1.04609337e-02, 2.22843010e-02, 4.17391993e-02],\n",
       "       [6.63453490e-02, 1.29976451e-01, 1.07413098e-01, ...,\n",
       "        1.89987868e-02, 5.53944707e-02, 1.19361036e-01],\n",
       "       [2.72117853e-01, 7.55511761e-01, 7.39497244e-01, ...,\n",
       "        3.79778370e-02, 1.02064863e-01, 2.26809993e-01],\n",
       "       ...,\n",
       "       [5.96319325e-03, 1.67052299e-02, 4.17377353e-02, ...,\n",
       "        4.01669275e-03, 3.52127198e-03, 3.80441896e-03],\n",
       "       [2.83434335e-03, 3.56018916e-03, 8.71523004e-03, ...,\n",
       "        1.03712059e-03, 1.07954605e-03, 1.25611818e-03],\n",
       "       [1.15276768e-03, 6.72629161e-04, 6.05149835e-04, ...,\n",
       "        7.02931284e-05, 2.38556546e-04, 5.81546745e-04]], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#載入音檔，給檔案路徑\n",
    "y, sr = librosa.load('./musicfile/3s/blues/blues1-1-0.wav', sr=22050, duration=60) #sr:採樣率 (一般音樂 44100Hz/s ,官方建議用 22050分析資料 )\n",
    "S = np.abs(librosa.stft(y))\n",
    "melspectrogram1 = librosa.feature.melspectrogram(S=S, sr=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63a92f0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "      <th>124</th>\n",
       "      <th>125</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "      <th>128</th>\n",
       "      <th>129</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.050674</td>\n",
       "      <td>0.030312</td>\n",
       "      <td>0.025406</td>\n",
       "      <td>0.024315</td>\n",
       "      <td>0.012315</td>\n",
       "      <td>0.006164</td>\n",
       "      <td>0.014241</td>\n",
       "      <td>0.013873</td>\n",
       "      <td>0.010669</td>\n",
       "      <td>0.015755</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005164</td>\n",
       "      <td>0.011249</td>\n",
       "      <td>0.012528</td>\n",
       "      <td>0.012837</td>\n",
       "      <td>0.016586</td>\n",
       "      <td>0.018324</td>\n",
       "      <td>0.007684</td>\n",
       "      <td>0.010461</td>\n",
       "      <td>0.022284</td>\n",
       "      <td>0.041739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.066345</td>\n",
       "      <td>0.129976</td>\n",
       "      <td>0.107413</td>\n",
       "      <td>0.076691</td>\n",
       "      <td>0.020498</td>\n",
       "      <td>0.006446</td>\n",
       "      <td>0.016772</td>\n",
       "      <td>0.039220</td>\n",
       "      <td>0.066459</td>\n",
       "      <td>0.078065</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017267</td>\n",
       "      <td>0.017884</td>\n",
       "      <td>0.043786</td>\n",
       "      <td>0.063578</td>\n",
       "      <td>0.065838</td>\n",
       "      <td>0.030999</td>\n",
       "      <td>0.019347</td>\n",
       "      <td>0.018999</td>\n",
       "      <td>0.055394</td>\n",
       "      <td>0.119361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.272118</td>\n",
       "      <td>0.755512</td>\n",
       "      <td>0.739497</td>\n",
       "      <td>0.311139</td>\n",
       "      <td>0.052058</td>\n",
       "      <td>0.029924</td>\n",
       "      <td>0.075942</td>\n",
       "      <td>0.178866</td>\n",
       "      <td>0.326679</td>\n",
       "      <td>0.425591</td>\n",
       "      <td>...</td>\n",
       "      <td>0.092396</td>\n",
       "      <td>0.183840</td>\n",
       "      <td>0.311131</td>\n",
       "      <td>0.420681</td>\n",
       "      <td>0.290623</td>\n",
       "      <td>0.090151</td>\n",
       "      <td>0.030807</td>\n",
       "      <td>0.037978</td>\n",
       "      <td>0.102065</td>\n",
       "      <td>0.226810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.927377</td>\n",
       "      <td>1.481547</td>\n",
       "      <td>0.719924</td>\n",
       "      <td>0.590422</td>\n",
       "      <td>0.508718</td>\n",
       "      <td>0.419812</td>\n",
       "      <td>0.481625</td>\n",
       "      <td>0.326965</td>\n",
       "      <td>0.471438</td>\n",
       "      <td>0.405098</td>\n",
       "      <td>...</td>\n",
       "      <td>0.262087</td>\n",
       "      <td>0.287539</td>\n",
       "      <td>0.619966</td>\n",
       "      <td>0.424500</td>\n",
       "      <td>0.182146</td>\n",
       "      <td>0.105921</td>\n",
       "      <td>0.068023</td>\n",
       "      <td>0.073098</td>\n",
       "      <td>0.173329</td>\n",
       "      <td>0.355255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.239525</td>\n",
       "      <td>1.695406</td>\n",
       "      <td>1.192340</td>\n",
       "      <td>1.144021</td>\n",
       "      <td>1.146533</td>\n",
       "      <td>1.025717</td>\n",
       "      <td>1.028877</td>\n",
       "      <td>0.587551</td>\n",
       "      <td>0.953037</td>\n",
       "      <td>1.152113</td>\n",
       "      <td>...</td>\n",
       "      <td>0.566601</td>\n",
       "      <td>0.864216</td>\n",
       "      <td>1.645551</td>\n",
       "      <td>1.331086</td>\n",
       "      <td>1.279500</td>\n",
       "      <td>1.235538</td>\n",
       "      <td>1.060055</td>\n",
       "      <td>0.835630</td>\n",
       "      <td>0.632158</td>\n",
       "      <td>0.840009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>0.023207</td>\n",
       "      <td>0.062729</td>\n",
       "      <td>0.140262</td>\n",
       "      <td>0.175829</td>\n",
       "      <td>0.173911</td>\n",
       "      <td>0.139660</td>\n",
       "      <td>0.096938</td>\n",
       "      <td>0.079723</td>\n",
       "      <td>0.055499</td>\n",
       "      <td>0.033147</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006715</td>\n",
       "      <td>0.011304</td>\n",
       "      <td>0.013573</td>\n",
       "      <td>0.033248</td>\n",
       "      <td>0.054490</td>\n",
       "      <td>0.054840</td>\n",
       "      <td>0.026046</td>\n",
       "      <td>0.010360</td>\n",
       "      <td>0.012095</td>\n",
       "      <td>0.014509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>0.014788</td>\n",
       "      <td>0.056769</td>\n",
       "      <td>0.114340</td>\n",
       "      <td>0.132946</td>\n",
       "      <td>0.140035</td>\n",
       "      <td>0.121783</td>\n",
       "      <td>0.096678</td>\n",
       "      <td>0.066042</td>\n",
       "      <td>0.043304</td>\n",
       "      <td>0.029626</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004107</td>\n",
       "      <td>0.005694</td>\n",
       "      <td>0.009640</td>\n",
       "      <td>0.030188</td>\n",
       "      <td>0.056823</td>\n",
       "      <td>0.046068</td>\n",
       "      <td>0.016963</td>\n",
       "      <td>0.007408</td>\n",
       "      <td>0.007329</td>\n",
       "      <td>0.009033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>0.005963</td>\n",
       "      <td>0.016705</td>\n",
       "      <td>0.041738</td>\n",
       "      <td>0.059501</td>\n",
       "      <td>0.067669</td>\n",
       "      <td>0.061723</td>\n",
       "      <td>0.040341</td>\n",
       "      <td>0.025296</td>\n",
       "      <td>0.020580</td>\n",
       "      <td>0.015758</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001664</td>\n",
       "      <td>0.002811</td>\n",
       "      <td>0.004184</td>\n",
       "      <td>0.012473</td>\n",
       "      <td>0.026615</td>\n",
       "      <td>0.021649</td>\n",
       "      <td>0.008872</td>\n",
       "      <td>0.004017</td>\n",
       "      <td>0.003521</td>\n",
       "      <td>0.003804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>0.002834</td>\n",
       "      <td>0.003560</td>\n",
       "      <td>0.008715</td>\n",
       "      <td>0.013223</td>\n",
       "      <td>0.012780</td>\n",
       "      <td>0.010876</td>\n",
       "      <td>0.007822</td>\n",
       "      <td>0.004653</td>\n",
       "      <td>0.005122</td>\n",
       "      <td>0.003720</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000468</td>\n",
       "      <td>0.000928</td>\n",
       "      <td>0.001639</td>\n",
       "      <td>0.004115</td>\n",
       "      <td>0.005539</td>\n",
       "      <td>0.004312</td>\n",
       "      <td>0.002101</td>\n",
       "      <td>0.001037</td>\n",
       "      <td>0.001080</td>\n",
       "      <td>0.001256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>0.001153</td>\n",
       "      <td>0.000673</td>\n",
       "      <td>0.000605</td>\n",
       "      <td>0.000915</td>\n",
       "      <td>0.001267</td>\n",
       "      <td>0.001046</td>\n",
       "      <td>0.000553</td>\n",
       "      <td>0.000528</td>\n",
       "      <td>0.000565</td>\n",
       "      <td>0.000411</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>0.000148</td>\n",
       "      <td>0.000359</td>\n",
       "      <td>0.000390</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.000145</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>0.000582</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>128 rows × 130 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6    \\\n",
       "0    0.050674  0.030312  0.025406  0.024315  0.012315  0.006164  0.014241   \n",
       "1    0.066345  0.129976  0.107413  0.076691  0.020498  0.006446  0.016772   \n",
       "2    0.272118  0.755512  0.739497  0.311139  0.052058  0.029924  0.075942   \n",
       "3    0.927377  1.481547  0.719924  0.590422  0.508718  0.419812  0.481625   \n",
       "4    1.239525  1.695406  1.192340  1.144021  1.146533  1.025717  1.028877   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "123  0.023207  0.062729  0.140262  0.175829  0.173911  0.139660  0.096938   \n",
       "124  0.014788  0.056769  0.114340  0.132946  0.140035  0.121783  0.096678   \n",
       "125  0.005963  0.016705  0.041738  0.059501  0.067669  0.061723  0.040341   \n",
       "126  0.002834  0.003560  0.008715  0.013223  0.012780  0.010876  0.007822   \n",
       "127  0.001153  0.000673  0.000605  0.000915  0.001267  0.001046  0.000553   \n",
       "\n",
       "          7         8         9    ...       120       121       122  \\\n",
       "0    0.013873  0.010669  0.015755  ...  0.005164  0.011249  0.012528   \n",
       "1    0.039220  0.066459  0.078065  ...  0.017267  0.017884  0.043786   \n",
       "2    0.178866  0.326679  0.425591  ...  0.092396  0.183840  0.311131   \n",
       "3    0.326965  0.471438  0.405098  ...  0.262087  0.287539  0.619966   \n",
       "4    0.587551  0.953037  1.152113  ...  0.566601  0.864216  1.645551   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "123  0.079723  0.055499  0.033147  ...  0.006715  0.011304  0.013573   \n",
       "124  0.066042  0.043304  0.029626  ...  0.004107  0.005694  0.009640   \n",
       "125  0.025296  0.020580  0.015758  ...  0.001664  0.002811  0.004184   \n",
       "126  0.004653  0.005122  0.003720  ...  0.000468  0.000928  0.001639   \n",
       "127  0.000528  0.000565  0.000411  ...  0.000048  0.000118  0.000148   \n",
       "\n",
       "          123       124       125       126       127       128       129  \n",
       "0    0.012837  0.016586  0.018324  0.007684  0.010461  0.022284  0.041739  \n",
       "1    0.063578  0.065838  0.030999  0.019347  0.018999  0.055394  0.119361  \n",
       "2    0.420681  0.290623  0.090151  0.030807  0.037978  0.102065  0.226810  \n",
       "3    0.424500  0.182146  0.105921  0.068023  0.073098  0.173329  0.355255  \n",
       "4    1.331086  1.279500  1.235538  1.060055  0.835630  0.632158  0.840009  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "123  0.033248  0.054490  0.054840  0.026046  0.010360  0.012095  0.014509  \n",
       "124  0.030188  0.056823  0.046068  0.016963  0.007408  0.007329  0.009033  \n",
       "125  0.012473  0.026615  0.021649  0.008872  0.004017  0.003521  0.003804  \n",
       "126  0.004115  0.005539  0.004312  0.002101  0.001037  0.001080  0.001256  \n",
       "127  0.000359  0.000390  0.000257  0.000145  0.000070  0.000239  0.000582  \n",
       "\n",
       "[128 rows x 130 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(melspectrogram1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018327fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y, sr = librosa.load('./musicfile/3s/blues/blues1-1-1.wav', sr=22050, duration=60) #sr:採樣率 (一般音樂 44100Hz/s ,官方建議用 22050分析資料 )\n",
    "S = np.abs(librosa.stft(y))\n",
    "melspectrogram2 = librosa.feature.melspectrogram(S=S, sr=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6c0806",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_genre = np.empty((0, 128, 130))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d46704",
   "metadata": {},
   "outputs": [],
   "source": [
    "melspectrogram1 = np.expand_dims(melspectrogram1, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6b9faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_genre = np.append(np_genre,melspectrogram1, axis=0)\n",
    "np_genre.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9d1cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "np1 = np.array(melspectrogram1)\n",
    "np1 = np.expand_dims(np1, axis = 0)\n",
    "print(np1.shape)\n",
    "\n",
    "np2 = np.array(melspectrogram2)\n",
    "np2 = np.expand_dims(np2, axis = 0)\n",
    "print(np2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5ff688",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_genre = np.append(np1,np2, axis=0)\n",
    "np_genre.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c321eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "np1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee27957",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_genre.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6babbacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mel(genre):\n",
    "    path = './musicfile/3s/%s/' %(genre)\n",
    "    id = 1  # Song ID\n",
    "    df_mel = pd.DataFrame()\n",
    "    X_spect = np.empty((0, 128, 130))\n",
    "    genres = []\n",
    "    dict_genres = {'blues':1, 'classical':2, 'country':3, 'disco':4, \n",
    "               'hiphop':5,'jazz':6, 'metal' :7, 'pop': 8 ,'reggae': 9 ,'rock':10}\n",
    "    file_data = [f for f in listdir(path) if isfile (join(path, f))]\n",
    "    \n",
    "    for line in file_data:\n",
    "        if ( line[-1:] == '\\n' ):   # 從換行前面取黨檔名\n",
    "            line = line[:-1]\n",
    "\n",
    "        songname = path + line # 將 目錄路徑跟檔名 合併成 檔案路徑\n",
    "        y, sr = librosa.load(songname, sr=22050, duration=60) # 用 librosa讀取檔案\n",
    "        S = np.abs(librosa.stft(y)) # 傅立葉轉換取振幅\n",
    "        melspectrogram = librosa.feature.melspectrogram(S=S, sr=sr)\n",
    "        melspectrogram = np.expand_dims(melspectrogram, axis = 0)\n",
    "        X_spect = np.append(X_spect,melspectrogram, axis=0)\n",
    "        genres.append(dict_genres[genre])\n",
    "        id = id+1\n",
    "            \n",
    "    y_arr = np.array(genres)\n",
    "#     print(X_spect)\n",
    "    print(X_spect.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6edfa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.perf_counter()\n",
    "\n",
    "genre = 'test'\n",
    "get_mel(genre)\n",
    "\n",
    "print(\"This time is being calculated\")\n",
    "\n",
    "end = time.perf_counter()\n",
    "\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75aec886",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "directory_list = list()\n",
    "for root, dirs, files in os.walk(\"./musicfile/3s/\", topdown=False):\n",
    "    for name in dirs:\n",
    "        directory_list.append(name)\n",
    "\n",
    "print(directory_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7ede27",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.perf_counter()\n",
    "\n",
    "id = 1  # Song ID\n",
    "# df_mel = pd.DataFrame()\n",
    "X_spect = np.empty((0, 128, 130))\n",
    "genres = []\n",
    "dict_genres = {'blues':1, 'classical':2, 'country':3, 'disco':4, \n",
    "           'hiphop':5,'jazz':6, 'metal' :7, 'pop': 8 ,'reggae': 9 ,'rock':10}\n",
    "directory_list = list()\n",
    "for root, dirs, files in os.walk(\"./musicfile/3s/\", topdown=False):\n",
    "    for name in dirs:\n",
    "        path = './musicfile/3s/%s/' %(name)\n",
    "\n",
    "        file_data = [f for f in listdir(path) if isfile (join(path, f))]\n",
    "\n",
    "        for line in file_data:\n",
    "            if ( line[-1:] == '\\n' ):   # 從換行前面取黨檔名\n",
    "                line = line[:-1]\n",
    "\n",
    "            songname = path + line # 將 目錄路徑跟檔名 合併成 檔案路徑\n",
    "            y, sr = librosa.load(songname, sr=22050, duration=60) # 用 librosa讀取檔案\n",
    "            S = np.abs(librosa.stft(y)) # 傅立葉轉換取振幅\n",
    "            melspectrogram = librosa.feature.melspectrogram(S=S, sr=sr)\n",
    "            melspectrogram = np.expand_dims(melspectrogram, axis = 0)\n",
    "            X_spect = np.append(X_spect,melspectrogram, axis=0)\n",
    "            genres.append(dict_genres[name])\n",
    "            print(songname)\n",
    "            id = id+1\n",
    "\n",
    "        y_arr = np.array(genres)\n",
    "\n",
    "print(y_arr.shape)\n",
    "print(X_spect.shape)\n",
    "\n",
    "\n",
    "print(\"This time is being calculated\")\n",
    "\n",
    "end = time.perf_counter()\n",
    "\n",
    "print(end - start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689bd049",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('df_arr', X_spect, y_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4806f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "npzfile = np.load('df_arr.npz')\n",
    "print(npzfile.files)\n",
    "X = npzfile['arr_0']\n",
    "y = npzfile['arr_1']\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02dba730",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y-1\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48df7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('df_zero_arr', X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53c14f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['arr_0', 'arr_1']\n",
      "(36480, 128, 130) (36480,)\n"
     ]
    }
   ],
   "source": [
    "npzfile = np.load('df_zero_arr.npz')\n",
    "print(npzfile.files)\n",
    "X = npzfile['arr_0']\n",
    "y = npzfile['arr_1']\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "deff2421",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36480, 10)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_onehot = np.eye(10)[y]\n",
    "y_onehot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dfd49f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "efe5c7ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36480, 128, 130)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means = np.mean(X,axis=(0,2))\n",
    "stds = np.std(X,axis=(0,2))\n",
    "means = means.reshape(1,-1,1)\n",
    "stds = stds.reshape(1,-1,1)\n",
    "X = (X-means)/stds\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7fb96289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36480, 128, 130, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X.reshape(36480, 128, 130, 1)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0843ead6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29184, 10)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y_onehot, test_size=0.2, random_state=42)\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "555e8626",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "num_classes = 10\n",
    "epochs = 10\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'testmodel.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1a9fdae0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_6 (Conv2D)           (None, 128, 130, 64)      640       \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 128, 130, 64)      0         \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 126, 128, 128)     73856     \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 126, 128, 128)     0         \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 63, 64, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 63, 64, 128)       0         \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 63, 64, 64)        73792     \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 63, 64, 64)        0         \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 61, 62, 64)        36928     \n",
      "                                                                 \n",
      " activation_8 (Activation)   (None, 61, 62, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 30, 31, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 30, 31, 64)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 59520)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               30474752  \n",
      "                                                                 \n",
      " activation_9 (Activation)   (None, 512)               0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      " activation_10 (Activation)  (None, 10)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 30,665,098\n",
      "Trainable params: 30,665,098\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# build our CNN model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64, (3, 3), padding='same',\n",
    "                 input_shape=X_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(128, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "# initiate Adam optimizer\n",
    "opt = keras.optimizers.Adam()\n",
    "\n",
    "# Let's train the model using Adam\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "checkpoint = ModelCheckpoint(model_path, monitor='val_loss', save_best_only=True, verbose=1)\n",
    "\n",
    "# earlystop\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "\n",
    "# Fit the model on the batches generated by datagen.flow().\n",
    "# model_history = model.fit_generator(datagen.flow(x_train, y_train,\n",
    "#                                  batch_size=batch_size),\n",
    "#                     epochs=epochs,\n",
    "#                     validation_data=(x_test, y_test),\n",
    "#                     workers=4,\n",
    "#                     callbacks=[earlystop])\n",
    "\n",
    "model_history = model.fit(X_train, \n",
    "                          y_train,\n",
    "                          batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    workers=4,\n",
    "                    callbacks=[earlystop])\n",
    "\n",
    "# loading our save model\n",
    "# print(\"Loading trained model\")\n",
    "# model = load_model(model_path)\n",
    "\n",
    "# Score trained model.\n",
    "scores = model.evaluate(X_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8cf6fdd1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_loss = model_history.history['loss']\n",
    "val_loss = model_history.history['val_loss']\n",
    "\n",
    "plt.plot(training_loss, label=\"training_loss\")\n",
    "plt.plot(val_loss, label=\"validation_loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Learning Curve\")\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5b7a1674",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "num_classes = 10\n",
    "epochs = 50\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'testmodel.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "554d8291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_14 (Conv2D)          (None, 126, 128, 64)      640       \n",
      "                                                                 \n",
      " activation_23 (Activation)  (None, 126, 128, 64)      0         \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 124, 126, 128)     73856     \n",
      "                                                                 \n",
      " activation_24 (Activation)  (None, 124, 126, 128)     0         \n",
      "                                                                 \n",
      " max_pooling2d_31 (MaxPoolin  (None, 62, 63, 128)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 62, 63, 128)       0         \n",
      "                                                                 \n",
      " conv2d_16 (Conv2D)          (None, 60, 61, 64)        73792     \n",
      "                                                                 \n",
      " activation_25 (Activation)  (None, 60, 61, 64)        0         \n",
      "                                                                 \n",
      " conv2d_17 (Conv2D)          (None, 58, 59, 32)        18464     \n",
      "                                                                 \n",
      " activation_26 (Activation)  (None, 58, 59, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d_32 (MaxPoolin  (None, 29, 29, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_18 (Dropout)        (None, 29, 29, 32)        0         \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 26912)             0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 512)               13779456  \n",
      "                                                                 \n",
      " activation_27 (Activation)  (None, 512)               0         \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      " activation_28 (Activation)  (None, 10)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,951,338\n",
      "Trainable params: 13,951,338\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "  6/456 [..............................] - ETA: 25:32 - loss: 2.5659 - accuracy: 0.1641"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [68]\u001b[0m, in \u001b[0;36m<cell line: 52>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     42\u001b[0m earlystop \u001b[38;5;241m=\u001b[39m EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# Fit the model on the batches generated by datagen.flow().\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# model_history = model.fit_generator(datagen.flow(x_train, y_train,\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m#                                  batch_size=batch_size),\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;66;03m#                     workers=4,\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m#                     callbacks=[earlystop])\u001b[39;00m\n\u001b[1;32m---> 52\u001b[0m model_history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m                          \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     57\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearlystop\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;66;03m# loading our save model\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m# print(\"Loading trained model\")\u001b[39;00m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;66;03m# model = load_model(model_path)\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \n\u001b[0;32m     64\u001b[0m \u001b[38;5;66;03m# Score trained model.\u001b[39;00m\n\u001b[0;32m     65\u001b[0m scores \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(X_test, y_test, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\python_course\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\python_course\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\python_course\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\python_course\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\python_course\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\python_course\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\python_course\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\python_course\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\python_course\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# build our CNN model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64, (3, 3), padding='valid',\n",
    "                 input_shape=X_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(128, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='valid'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "# initiate Adam optimizer\n",
    "opt = keras.optimizers.Adam()\n",
    "\n",
    "# Let's train the model using Adam\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "checkpoint = ModelCheckpoint(model_path, monitor='val_loss', save_best_only=True, verbose=1)\n",
    "\n",
    "# earlystop\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "\n",
    "# Fit the model on the batches generated by datagen.flow().\n",
    "# model_history = model.fit_generator(datagen.flow(x_train, y_train,\n",
    "#                                  batch_size=batch_size),\n",
    "#                     epochs=epochs,\n",
    "#                     validation_data=(x_test, y_test),\n",
    "#                     workers=4,\n",
    "#                     callbacks=[earlystop])\n",
    "\n",
    "model_history = model.fit(X_train, \n",
    "                          y_train,\n",
    "                          batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    workers=4,\n",
    "                    callbacks=[earlystop])\n",
    "\n",
    "# loading our save model\n",
    "# print(\"Loading trained model\")\n",
    "# model = load_model(model_path)\n",
    "\n",
    "# Score trained model.\n",
    "scores = model.evaluate(X_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1104776",
   "metadata": {},
   "source": [
    "# crnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ef01a984",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Dense, TimeDistributed, LSTM, Dropout, Activation, ELU\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, Conv2D, BatchNormalization, Lambda\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard, ReduceLROnPlateau\n",
    "from keras import backend\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "21156663",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "num_classes = 10\n",
    "n_features = X_train.shape[2]\n",
    "n_time = X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "90ac4fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_LAYERS = 3\n",
    "FILTER_LENGTH = 5\n",
    "CONV_FILTER_COUNT = 56\n",
    "BATCH_SIZE = 32\n",
    "LSTM_COUNT = 96\n",
    "EPOCH_COUNT = 70\n",
    "NUM_HIDDEN = 64\n",
    "L2_regularization = 0.001\n",
    "\n",
    "def conv_recurrent_model_build(model_input):\n",
    "    layer = model_input\n",
    "    \n",
    "    ### 3 1D Convolution Layers\n",
    "    for i in range(N_LAYERS):\n",
    "        # give name to the layers\n",
    "        layer = Conv1D(\n",
    "                filters=CONV_FILTER_COUNT,\n",
    "                kernel_size=FILTER_LENGTH,\n",
    "                kernel_regularizer=regularizers.l2(L2_regularization),  # Tried 0.001\n",
    "                name='convolution_' + str(i + 1)\n",
    "            )(layer)\n",
    "        layer = BatchNormalization(momentum=0.9)(layer)\n",
    "        layer = Activation('relu')(layer)\n",
    "        layer = MaxPooling1D(2)(layer)\n",
    "        layer = Dropout(0.4)(layer)\n",
    "    \n",
    "    ## LSTM Layer\n",
    "    layer = LSTM(LSTM_COUNT, return_sequences=False)(layer)\n",
    "    layer = Dropout(0.4)(layer)\n",
    "    \n",
    "    ## Dense Layer\n",
    "    layer = Dense(NUM_HIDDEN, kernel_regularizer=regularizers.l2(L2_regularization), name='dense1')(layer)\n",
    "    layer = Dropout(0.4)(layer)\n",
    "    \n",
    "    ## Softmax Output\n",
    "    layer = Dense(num_classes)(layer)\n",
    "    layer = Activation('softmax', name='output_realtime')(layer)\n",
    "    model_output = layer\n",
    "    model = Model(model_input, model_output)\n",
    "    \n",
    "    \n",
    "    opt = Adam(lr=0.001)\n",
    "    model.compile(\n",
    "            loss='categorical_crossentropy',\n",
    "            optimizer=opt,\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "    \n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "834e7b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    n_features = X_train.shape[2]\n",
    "    input_shape = (None, n_features)\n",
    "    model_input = Input(input_shape, name='input')\n",
    "    \n",
    "    model = conv_recurrent_model_build(model_input)\n",
    "    \n",
    "#     tb_callback = TensorBoard(log_dir='./logs/4', histogram_freq=1, batch_size=32, write_graph=True, write_grads=False,\n",
    "#                               write_images=False, embeddings_freq=0, embeddings_layer_names=None,\n",
    "#                               embeddings_metadata=None)\n",
    "    checkpoint_callback = ModelCheckpoint('./models/crnn/weights.best.h5', monitor='val_accuracy', verbose=1,\n",
    "                                          save_best_only=True, mode='max')\n",
    "    \n",
    "    reducelr_callback = ReduceLROnPlateau(\n",
    "                monitor='val_accuracy', factor=0.5, patience=10, min_delta=0.01,\n",
    "                verbose=1\n",
    "            )\n",
    "    callbacks_list = [checkpoint_callback, reducelr_callback]\n",
    "\n",
    "    # Fit the model and get training history.\n",
    "    print('Training...')\n",
    "    history = model.fit(X_train, y_train, batch_size=BATCH_SIZE, epochs=EPOCH_COUNT,\n",
    "                        validation_data=(X_test, y_test), verbose=1, callbacks=callbacks_list)\n",
    "\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cfe9af8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_summary_stats(history):\n",
    "    # List all data in history\n",
    "    print(history.history.keys())\n",
    "\n",
    "    # Summarize history for accuracy\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    # Summarize history for loss\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "021898a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, None, 130)]       0         \n",
      "                                                                 \n",
      " convolution_1 (Conv1D)      (None, None, 56)          36456     \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, None, 56)         224       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_20 (Activation)  (None, None, 56)          0         \n",
      "                                                                 \n",
      " max_pooling1d_3 (MaxPooling  (None, None, 56)         0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, None, 56)          0         \n",
      "                                                                 \n",
      " convolution_2 (Conv1D)      (None, None, 56)          15736     \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, None, 56)         224       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_21 (Activation)  (None, None, 56)          0         \n",
      "                                                                 \n",
      " max_pooling1d_4 (MaxPooling  (None, None, 56)         0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, None, 56)          0         \n",
      "                                                                 \n",
      " convolution_3 (Conv1D)      (None, None, 56)          15736     \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, None, 56)         224       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_22 (Activation)  (None, None, 56)          0         \n",
      "                                                                 \n",
      " max_pooling1d_5 (MaxPooling  (None, None, 56)         0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, None, 56)          0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 96)                58752     \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 96)                0         \n",
      "                                                                 \n",
      " dense1 (Dense)              (None, 64)                6208      \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      " output_realtime (Activation  (None, 10)               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 134,210\n",
      "Trainable params: 133,874\n",
      "Non-trainable params: 336\n",
      "_________________________________________________________________\n",
      "None\n",
      "Training...\n",
      "Epoch 1/70\n",
      "911/912 [============================>.] - ETA: 0s - loss: 1.9865 - accuracy: 0.3612\n",
      "Epoch 1: val_loss improved from -inf to 1.69392, saving model to ./models/crnn\\weights.best.h5\n",
      "912/912 [==============================] - 17s 17ms/step - loss: 1.9862 - accuracy: 0.3614 - val_loss: 1.6939 - val_accuracy: 0.4516 - lr: 0.0010\n",
      "Epoch 2/70\n",
      "910/912 [============================>.] - ETA: 0s - loss: 1.7131 - accuracy: 0.4475\n",
      "Epoch 2: val_loss did not improve from 1.69392\n",
      "912/912 [==============================] - 14s 16ms/step - loss: 1.7131 - accuracy: 0.4476 - val_loss: 1.4652 - val_accuracy: 0.5414 - lr: 0.0010\n",
      "Epoch 3/70\n",
      "909/912 [============================>.] - ETA: 0s - loss: 1.5957 - accuracy: 0.4872\n",
      "Epoch 3: val_loss did not improve from 1.69392\n",
      "912/912 [==============================] - 16s 17ms/step - loss: 1.5959 - accuracy: 0.4870 - val_loss: 1.4287 - val_accuracy: 0.5469 - lr: 0.0010\n",
      "Epoch 4/70\n",
      "909/912 [============================>.] - ETA: 0s - loss: 1.5307 - accuracy: 0.5103\n",
      "Epoch 4: val_loss did not improve from 1.69392\n",
      "912/912 [==============================] - 16s 17ms/step - loss: 1.5311 - accuracy: 0.5103 - val_loss: 1.3610 - val_accuracy: 0.5676 - lr: 0.0010\n",
      "Epoch 5/70\n",
      "911/912 [============================>.] - ETA: 0s - loss: 1.4667 - accuracy: 0.5341\n",
      "Epoch 5: val_loss did not improve from 1.69392\n",
      "912/912 [==============================] - 16s 17ms/step - loss: 1.4665 - accuracy: 0.5342 - val_loss: 1.2539 - val_accuracy: 0.6133 - lr: 0.0010\n",
      "Epoch 6/70\n",
      "912/912 [==============================] - ETA: 0s - loss: 1.4250 - accuracy: 0.5513\n",
      "Epoch 6: val_loss did not improve from 1.69392\n",
      "912/912 [==============================] - 16s 17ms/step - loss: 1.4250 - accuracy: 0.5513 - val_loss: 1.2348 - val_accuracy: 0.6247 - lr: 0.0010\n",
      "Epoch 7/70\n",
      "909/912 [============================>.] - ETA: 0s - loss: 1.4030 - accuracy: 0.5625\n",
      "Epoch 7: val_loss did not improve from 1.69392\n",
      "912/912 [==============================] - 16s 17ms/step - loss: 1.4037 - accuracy: 0.5623 - val_loss: 1.2480 - val_accuracy: 0.6021 - lr: 0.0010\n",
      "Epoch 8/70\n",
      "909/912 [============================>.] - ETA: 0s - loss: 1.3692 - accuracy: 0.5726\n",
      "Epoch 8: val_loss did not improve from 1.69392\n",
      "912/912 [==============================] - 16s 17ms/step - loss: 1.3697 - accuracy: 0.5725 - val_loss: 1.1861 - val_accuracy: 0.6406 - lr: 0.0010\n",
      "Epoch 9/70\n",
      "912/912 [==============================] - ETA: 0s - loss: 1.3522 - accuracy: 0.5838\n",
      "Epoch 9: val_loss did not improve from 1.69392\n",
      "912/912 [==============================] - 16s 17ms/step - loss: 1.3522 - accuracy: 0.5838 - val_loss: 1.1725 - val_accuracy: 0.6487 - lr: 0.0010\n",
      "Epoch 10/70\n",
      "912/912 [==============================] - ETA: 0s - loss: 1.3273 - accuracy: 0.5931\n",
      "Epoch 10: val_loss did not improve from 1.69392\n",
      "912/912 [==============================] - 16s 17ms/step - loss: 1.3273 - accuracy: 0.5931 - val_loss: 1.1647 - val_accuracy: 0.6497 - lr: 0.0010\n",
      "Epoch 11/70\n",
      "912/912 [==============================] - ETA: 0s - loss: 1.3200 - accuracy: 0.6002\n",
      "Epoch 11: val_loss did not improve from 1.69392\n",
      "912/912 [==============================] - 16s 17ms/step - loss: 1.3200 - accuracy: 0.6002 - val_loss: 1.1590 - val_accuracy: 0.6523 - lr: 0.0010\n",
      "Epoch 12/70\n",
      "909/912 [============================>.] - ETA: 0s - loss: 1.3003 - accuracy: 0.6087\n",
      "Epoch 12: val_loss did not improve from 1.69392\n",
      "912/912 [==============================] - 16s 18ms/step - loss: 1.3005 - accuracy: 0.6084 - val_loss: 1.0918 - val_accuracy: 0.6791 - lr: 0.0010\n",
      "Epoch 13/70\n",
      "910/912 [============================>.] - ETA: 0s - loss: 1.2859 - accuracy: 0.6118\n",
      "Epoch 13: val_loss did not improve from 1.69392\n",
      "912/912 [==============================] - 16s 18ms/step - loss: 1.2858 - accuracy: 0.6119 - val_loss: 1.0951 - val_accuracy: 0.6796 - lr: 0.0010\n",
      "Epoch 14/70\n",
      "910/912 [============================>.] - ETA: 0s - loss: 1.2838 - accuracy: 0.6154\n",
      "Epoch 14: val_loss did not improve from 1.69392\n",
      "912/912 [==============================] - 16s 18ms/step - loss: 1.2834 - accuracy: 0.6155 - val_loss: 1.0956 - val_accuracy: 0.6790 - lr: 0.0010\n",
      "Epoch 15/70\n",
      "911/912 [============================>.] - ETA: 0s - loss: 1.2754 - accuracy: 0.6189\n",
      "Epoch 15: val_loss did not improve from 1.69392\n",
      "912/912 [==============================] - 16s 18ms/step - loss: 1.2751 - accuracy: 0.6190 - val_loss: 1.2564 - val_accuracy: 0.6240 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/70\n",
      "909/912 [============================>.] - ETA: 0s - loss: 1.2594 - accuracy: 0.6245\n",
      "Epoch 16: val_loss did not improve from 1.69392\n",
      "912/912 [==============================] - 16s 18ms/step - loss: 1.2589 - accuracy: 0.6245 - val_loss: 1.0576 - val_accuracy: 0.6874 - lr: 0.0010\n",
      "Epoch 17/70\n",
      "911/912 [============================>.] - ETA: 0s - loss: 1.2546 - accuracy: 0.6311\n",
      "Epoch 17: val_loss did not improve from 1.69392\n",
      "912/912 [==============================] - 16s 18ms/step - loss: 1.2550 - accuracy: 0.6310 - val_loss: 1.1013 - val_accuracy: 0.6735 - lr: 0.0010\n",
      "Epoch 18/70\n",
      "912/912 [==============================] - ETA: 0s - loss: 1.2492 - accuracy: 0.6332\n",
      "Epoch 18: val_loss did not improve from 1.69392\n",
      "912/912 [==============================] - 16s 18ms/step - loss: 1.2492 - accuracy: 0.6332 - val_loss: 1.0610 - val_accuracy: 0.6927 - lr: 0.0010\n",
      "Epoch 19/70\n",
      "909/912 [============================>.] - ETA: 0s - loss: 1.2353 - accuracy: 0.6389\n",
      "Epoch 19: val_loss did not improve from 1.69392\n",
      "912/912 [==============================] - 16s 18ms/step - loss: 1.2352 - accuracy: 0.6389 - val_loss: 1.0318 - val_accuracy: 0.7012 - lr: 0.0010\n",
      "Epoch 20/70\n",
      "912/912 [==============================] - ETA: 0s - loss: 1.2256 - accuracy: 0.6415\n",
      "Epoch 20: val_loss did not improve from 1.69392\n",
      "912/912 [==============================] - 17s 18ms/step - loss: 1.2256 - accuracy: 0.6415 - val_loss: 1.0113 - val_accuracy: 0.7116 - lr: 0.0010\n",
      "Epoch 21/70\n",
      "910/912 [============================>.] - ETA: 0s - loss: 1.2272 - accuracy: 0.6391\n",
      "Epoch 21: val_loss did not improve from 1.69392\n",
      "912/912 [==============================] - 16s 18ms/step - loss: 1.2266 - accuracy: 0.6393 - val_loss: 1.0223 - val_accuracy: 0.7096 - lr: 0.0010\n",
      "Epoch 22/70\n",
      "911/912 [============================>.] - ETA: 0s - loss: 1.2162 - accuracy: 0.6460\n",
      "Epoch 22: val_loss did not improve from 1.69392\n",
      "912/912 [==============================] - 17s 18ms/step - loss: 1.2162 - accuracy: 0.6460 - val_loss: 1.0354 - val_accuracy: 0.7059 - lr: 0.0010\n",
      "Epoch 23/70\n",
      "909/912 [============================>.] - ETA: 0s - loss: 1.2188 - accuracy: 0.6458\n",
      "Epoch 23: val_loss did not improve from 1.69392\n",
      "912/912 [==============================] - 17s 18ms/step - loss: 1.2190 - accuracy: 0.6457 - val_loss: 1.0826 - val_accuracy: 0.6871 - lr: 0.0010\n",
      "Epoch 24/70\n",
      "910/912 [============================>.] - ETA: 0s - loss: 1.2061 - accuracy: 0.6509\n",
      "Epoch 24: val_loss did not improve from 1.69392\n",
      "912/912 [==============================] - 17s 18ms/step - loss: 1.2060 - accuracy: 0.6509 - val_loss: 0.9857 - val_accuracy: 0.7240 - lr: 0.0010\n",
      "Epoch 25/70\n",
      "912/912 [==============================] - ETA: 0s - loss: 1.1965 - accuracy: 0.6538\n",
      "Epoch 25: val_loss did not improve from 1.69392\n",
      "912/912 [==============================] - 17s 19ms/step - loss: 1.1965 - accuracy: 0.6538 - val_loss: 1.0006 - val_accuracy: 0.7168 - lr: 0.0010\n",
      "Epoch 26/70\n",
      "912/912 [==============================] - ETA: 0s - loss: 1.1907 - accuracy: 0.6590\n",
      "Epoch 26: val_loss did not improve from 1.69392\n",
      "912/912 [==============================] - 17s 19ms/step - loss: 1.1907 - accuracy: 0.6590 - val_loss: 0.9652 - val_accuracy: 0.7290 - lr: 0.0010\n",
      "Epoch 27/70\n",
      "911/912 [============================>.] - ETA: 0s - loss: 1.1894 - accuracy: 0.6588\n",
      "Epoch 27: val_loss did not improve from 1.69392\n",
      "912/912 [==============================] - 17s 19ms/step - loss: 1.1892 - accuracy: 0.6589 - val_loss: 0.9794 - val_accuracy: 0.7164 - lr: 0.0010\n",
      "Epoch 28/70\n",
      "910/912 [============================>.] - ETA: 0s - loss: 1.1857 - accuracy: 0.6616\n",
      "Epoch 28: val_loss did not improve from 1.69392\n",
      "912/912 [==============================] - 17s 19ms/step - loss: 1.1852 - accuracy: 0.6617 - val_loss: 0.9555 - val_accuracy: 0.7348 - lr: 0.0010\n",
      "Epoch 29/70\n",
      "910/912 [============================>.] - ETA: 0s - loss: 1.1839 - accuracy: 0.6607\n",
      "Epoch 29: val_loss did not improve from 1.69392\n",
      "912/912 [==============================] - 17s 19ms/step - loss: 1.1838 - accuracy: 0.6608 - val_loss: 0.9508 - val_accuracy: 0.7341 - lr: 0.0010\n",
      "Epoch 30/70\n",
      "911/912 [============================>.] - ETA: 0s - loss: 1.1813 - accuracy: 0.6628\n",
      "Epoch 30: val_loss did not improve from 1.69392\n",
      "912/912 [==============================] - 17s 19ms/step - loss: 1.1809 - accuracy: 0.6629 - val_loss: 0.9459 - val_accuracy: 0.7367 - lr: 0.0010\n",
      "Epoch 31/70\n",
      "910/912 [============================>.] - ETA: 0s - loss: 1.1779 - accuracy: 0.6621\n",
      "Epoch 31: val_loss did not improve from 1.69392\n",
      "912/912 [==============================] - 17s 19ms/step - loss: 1.1778 - accuracy: 0.6622 - val_loss: 0.9558 - val_accuracy: 0.7279 - lr: 0.0010\n",
      "Epoch 32/70\n",
      "912/912 [==============================] - ETA: 0s - loss: 1.1662 - accuracy: 0.6660\n",
      "Epoch 32: val_loss did not improve from 1.69392\n",
      "912/912 [==============================] - 17s 19ms/step - loss: 1.1662 - accuracy: 0.6660 - val_loss: 0.9893 - val_accuracy: 0.7264 - lr: 0.0010\n",
      "Epoch 33/70\n",
      "911/912 [============================>.] - ETA: 0s - loss: 1.1649 - accuracy: 0.6710\n",
      "Epoch 33: val_loss did not improve from 1.69392\n",
      "912/912 [==============================] - 17s 18ms/step - loss: 1.1647 - accuracy: 0.6711 - val_loss: 0.9660 - val_accuracy: 0.7290 - lr: 0.0010\n",
      "Epoch 34/70\n",
      "911/912 [============================>.] - ETA: 0s - loss: 1.1678 - accuracy: 0.6715\n",
      "Epoch 34: val_loss did not improve from 1.69392\n",
      "912/912 [==============================] - 17s 18ms/step - loss: 1.1680 - accuracy: 0.6714 - val_loss: 1.0085 - val_accuracy: 0.7119 - lr: 0.0010\n",
      "Epoch 35/70\n",
      "911/912 [============================>.] - ETA: 0s - loss: 1.1567 - accuracy: 0.6738\n",
      "Epoch 35: val_loss did not improve from 1.69392\n",
      "912/912 [==============================] - 17s 19ms/step - loss: 1.1572 - accuracy: 0.6737 - val_loss: 0.9926 - val_accuracy: 0.7194 - lr: 0.0010\n",
      "Epoch 36/70\n",
      "912/912 [==============================] - ETA: 0s - loss: 1.1578 - accuracy: 0.6700\n",
      "Epoch 36: val_loss did not improve from 1.69392\n",
      "912/912 [==============================] - 17s 19ms/step - loss: 1.1578 - accuracy: 0.6700 - val_loss: 0.9341 - val_accuracy: 0.7458 - lr: 0.0010\n",
      "Epoch 37/70\n",
      "910/912 [============================>.] - ETA: 0s - loss: 1.1493 - accuracy: 0.6753\n",
      "Epoch 37: val_loss did not improve from 1.69392\n",
      "912/912 [==============================] - 17s 19ms/step - loss: 1.1491 - accuracy: 0.6753 - val_loss: 0.9453 - val_accuracy: 0.7421 - lr: 0.0010\n",
      "Epoch 38/70\n",
      "910/912 [============================>.] - ETA: 0s - loss: 1.1576 - accuracy: 0.6729\n",
      "Epoch 38: val_loss did not improve from 1.69392\n",
      "912/912 [==============================] - 17s 19ms/step - loss: 1.1576 - accuracy: 0.6730 - val_loss: 0.9575 - val_accuracy: 0.7322 - lr: 0.0010\n",
      "Epoch 39/70\n",
      "910/912 [============================>.] - ETA: 0s - loss: 1.1533 - accuracy: 0.6735\n",
      "Epoch 39: val_loss did not improve from 1.69392\n",
      "912/912 [==============================] - 17s 19ms/step - loss: 1.1541 - accuracy: 0.6731 - val_loss: 0.9239 - val_accuracy: 0.7453 - lr: 0.0010\n",
      "Epoch 40/70\n",
      "910/912 [============================>.] - ETA: 0s - loss: 1.1452 - accuracy: 0.6755\n",
      "Epoch 40: val_loss did not improve from 1.69392\n",
      "912/912 [==============================] - 18s 19ms/step - loss: 1.1459 - accuracy: 0.6752 - val_loss: 0.8966 - val_accuracy: 0.7592 - lr: 0.0010\n",
      "Epoch 41/70\n",
      "910/912 [============================>.] - ETA: 0s - loss: 1.1487 - accuracy: 0.6765\n",
      "Epoch 41: val_loss did not improve from 1.69392\n",
      "912/912 [==============================] - 18s 19ms/step - loss: 1.1485 - accuracy: 0.6765 - val_loss: 0.9048 - val_accuracy: 0.7608 - lr: 0.0010\n",
      "Epoch 42/70\n",
      "912/912 [==============================] - ETA: 0s - loss: 1.1336 - accuracy: 0.6832\n",
      "Epoch 42: val_loss did not improve from 1.69392\n",
      "912/912 [==============================] - 18s 19ms/step - loss: 1.1336 - accuracy: 0.6832 - val_loss: 0.9106 - val_accuracy: 0.7549 - lr: 0.0010\n",
      "Epoch 43/70\n",
      "911/912 [============================>.] - ETA: 0s - loss: 1.1324 - accuracy: 0.6824\n",
      "Epoch 43: val_loss did not improve from 1.69392\n",
      "912/912 [==============================] - 18s 19ms/step - loss: 1.1321 - accuracy: 0.6825 - val_loss: 0.9363 - val_accuracy: 0.7430 - lr: 0.0010\n",
      "Epoch 44/70\n",
      "911/912 [============================>.] - ETA: 0s - loss: 1.1319 - accuracy: 0.6812\n",
      "Epoch 44: val_loss did not improve from 1.69392\n",
      "912/912 [==============================] - 18s 20ms/step - loss: 1.1319 - accuracy: 0.6811 - val_loss: 0.8922 - val_accuracy: 0.7611 - lr: 0.0010\n",
      "Epoch 45/70\n",
      "911/912 [============================>.] - ETA: 0s - loss: 1.1390 - accuracy: 0.6825\n",
      "Epoch 45: val_loss did not improve from 1.69392\n",
      "912/912 [==============================] - 18s 20ms/step - loss: 1.1389 - accuracy: 0.6824 - val_loss: 0.8760 - val_accuracy: 0.7640 - lr: 0.0010\n",
      "Epoch 46/70\n",
      "910/912 [============================>.] - ETA: 0s - loss: 1.1357 - accuracy: 0.6794\n",
      "Epoch 46: val_loss did not improve from 1.69392\n",
      "912/912 [==============================] - 18s 20ms/step - loss: 1.1359 - accuracy: 0.6793 - val_loss: 0.9109 - val_accuracy: 0.7534 - lr: 0.0010\n",
      "Epoch 47/70\n",
      "910/912 [============================>.] - ETA: 0s - loss: 1.1280 - accuracy: 0.6841\n",
      "Epoch 47: val_loss did not improve from 1.69392\n",
      "912/912 [==============================] - 18s 20ms/step - loss: 1.1280 - accuracy: 0.6841 - val_loss: 0.9057 - val_accuracy: 0.7533 - lr: 0.0010\n",
      "Epoch 48/70\n",
      "910/912 [============================>.] - ETA: 0s - loss: 1.1266 - accuracy: 0.6866\n",
      "Epoch 48: val_loss did not improve from 1.69392\n",
      "912/912 [==============================] - 18s 20ms/step - loss: 1.1267 - accuracy: 0.6867 - val_loss: 0.9718 - val_accuracy: 0.7309 - lr: 0.0010\n",
      "Epoch 49/70\n",
      "910/912 [============================>.] - ETA: 0s - loss: 1.1181 - accuracy: 0.6907\n",
      "Epoch 49: val_loss did not improve from 1.69392\n",
      "912/912 [==============================] - 18s 20ms/step - loss: 1.1183 - accuracy: 0.6906 - val_loss: 0.9170 - val_accuracy: 0.7508 - lr: 0.0010\n",
      "Epoch 50/70\n",
      "910/912 [============================>.] - ETA: 0s - loss: 1.1220 - accuracy: 0.6855\n",
      "Epoch 50: val_loss did not improve from 1.69392\n",
      "912/912 [==============================] - 18s 20ms/step - loss: 1.1216 - accuracy: 0.6855 - val_loss: 0.8937 - val_accuracy: 0.7574 - lr: 0.0010\n",
      "Epoch 51/70\n",
      "910/912 [============================>.] - ETA: 0s - loss: 1.1167 - accuracy: 0.6887\n",
      "Epoch 51: val_loss did not improve from 1.69392\n",
      "912/912 [==============================] - 18s 20ms/step - loss: 1.1176 - accuracy: 0.6885 - val_loss: 0.9127 - val_accuracy: 0.7566 - lr: 0.0010\n",
      "Epoch 52/70\n",
      "910/912 [============================>.] - ETA: 0s - loss: 1.1109 - accuracy: 0.6905\n",
      "Epoch 52: val_loss did not improve from 1.69392\n",
      "912/912 [==============================] - 18s 20ms/step - loss: 1.1102 - accuracy: 0.6907 - val_loss: 0.9076 - val_accuracy: 0.7545 - lr: 0.0010\n",
      "Epoch 53/70\n",
      "910/912 [============================>.] - ETA: 0s - loss: 1.1101 - accuracy: 0.6911\n",
      "Epoch 53: val_loss did not improve from 1.69392\n",
      "912/912 [==============================] - 18s 20ms/step - loss: 1.1098 - accuracy: 0.6913 - val_loss: 0.8939 - val_accuracy: 0.7611 - lr: 0.0010\n",
      "Epoch 54/70\n",
      "910/912 [============================>.] - ETA: 0s - loss: 1.1069 - accuracy: 0.6941\n",
      "Epoch 54: val_loss did not improve from 1.69392\n",
      "912/912 [==============================] - 18s 20ms/step - loss: 1.1067 - accuracy: 0.6941 - val_loss: 0.9229 - val_accuracy: 0.7471 - lr: 0.0010\n",
      "Epoch 55/70\n",
      "910/912 [============================>.] - ETA: 0s - loss: 1.1122 - accuracy: 0.6900\n",
      "Epoch 55: val_loss did not improve from 1.69392\n",
      "\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "912/912 [==============================] - 19s 20ms/step - loss: 1.1130 - accuracy: 0.6896 - val_loss: 0.8973 - val_accuracy: 0.7600 - lr: 0.0010\n",
      "Epoch 56/70\n",
      "911/912 [============================>.] - ETA: 0s - loss: 1.0428 - accuracy: 0.7132\n",
      "Epoch 56: val_loss did not improve from 1.69392\n",
      "912/912 [==============================] - 19s 20ms/step - loss: 1.0429 - accuracy: 0.7132 - val_loss: 0.8516 - val_accuracy: 0.7744 - lr: 5.0000e-04\n",
      "Epoch 57/70\n",
      "912/912 [==============================] - ETA: 0s - loss: 1.0070 - accuracy: 0.7211\n",
      "Epoch 57: val_loss did not improve from 1.69392\n",
      "912/912 [==============================] - 19s 21ms/step - loss: 1.0070 - accuracy: 0.7211 - val_loss: 0.8304 - val_accuracy: 0.7682 - lr: 5.0000e-04\n",
      "Epoch 58/70\n",
      "912/912 [==============================] - ETA: 0s - loss: 0.9931 - accuracy: 0.7215\n",
      "Epoch 58: val_loss did not improve from 1.69392\n",
      "912/912 [==============================] - 19s 21ms/step - loss: 0.9931 - accuracy: 0.7215 - val_loss: 0.7625 - val_accuracy: 0.8006 - lr: 5.0000e-04\n",
      "Epoch 59/70\n",
      "910/912 [============================>.] - ETA: 0s - loss: 0.9846 - accuracy: 0.7224\n",
      "Epoch 59: val_loss did not improve from 1.69392\n",
      "912/912 [==============================] - 19s 21ms/step - loss: 0.9844 - accuracy: 0.7226 - val_loss: 0.7945 - val_accuracy: 0.7793 - lr: 5.0000e-04\n",
      "Epoch 60/70\n",
      "912/912 [==============================] - ETA: 0s - loss: 0.9724 - accuracy: 0.7282\n",
      "Epoch 60: val_loss did not improve from 1.69392\n",
      "912/912 [==============================] - 19s 21ms/step - loss: 0.9724 - accuracy: 0.7282 - val_loss: 0.7661 - val_accuracy: 0.7892 - lr: 5.0000e-04\n",
      "Epoch 61/70\n",
      "912/912 [==============================] - ETA: 0s - loss: 0.9619 - accuracy: 0.7271\n",
      "Epoch 61: val_loss did not improve from 1.69392\n",
      "912/912 [==============================] - 19s 21ms/step - loss: 0.9619 - accuracy: 0.7271 - val_loss: 0.7663 - val_accuracy: 0.7887 - lr: 5.0000e-04\n",
      "Epoch 62/70\n",
      "911/912 [============================>.] - ETA: 0s - loss: 0.9606 - accuracy: 0.7273\n",
      "Epoch 62: val_loss did not improve from 1.69392\n",
      "912/912 [==============================] - 19s 21ms/step - loss: 0.9609 - accuracy: 0.7272 - val_loss: 0.7453 - val_accuracy: 0.7937 - lr: 5.0000e-04\n",
      "Epoch 63/70\n",
      "910/912 [============================>.] - ETA: 0s - loss: 0.9540 - accuracy: 0.7338\n",
      "Epoch 63: val_loss did not improve from 1.69392\n",
      "912/912 [==============================] - 19s 20ms/step - loss: 0.9541 - accuracy: 0.7337 - val_loss: 0.7629 - val_accuracy: 0.7892 - lr: 5.0000e-04\n",
      "Epoch 64/70\n",
      "912/912 [==============================] - ETA: 0s - loss: 0.9494 - accuracy: 0.7315\n",
      "Epoch 64: val_loss did not improve from 1.69392\n",
      "912/912 [==============================] - 19s 21ms/step - loss: 0.9494 - accuracy: 0.7315 - val_loss: 0.7417 - val_accuracy: 0.7961 - lr: 5.0000e-04\n",
      "Epoch 65/70\n",
      "910/912 [============================>.] - ETA: 0s - loss: 0.9492 - accuracy: 0.7292\n",
      "Epoch 65: val_loss did not improve from 1.69392\n",
      "912/912 [==============================] - 19s 21ms/step - loss: 0.9492 - accuracy: 0.7291 - val_loss: 0.7725 - val_accuracy: 0.7823 - lr: 5.0000e-04\n",
      "Epoch 66/70\n",
      "912/912 [==============================] - ETA: 0s - loss: 0.9440 - accuracy: 0.7323\n",
      "Epoch 66: val_loss did not improve from 1.69392\n",
      "912/912 [==============================] - 19s 21ms/step - loss: 0.9440 - accuracy: 0.7323 - val_loss: 0.7447 - val_accuracy: 0.7919 - lr: 5.0000e-04\n",
      "Epoch 67/70\n",
      "910/912 [============================>.] - ETA: 0s - loss: 0.9398 - accuracy: 0.7337\n",
      "Epoch 67: val_loss did not improve from 1.69392\n",
      "912/912 [==============================] - 19s 21ms/step - loss: 0.9393 - accuracy: 0.7339 - val_loss: 0.7708 - val_accuracy: 0.7822 - lr: 5.0000e-04\n",
      "Epoch 68/70\n",
      "910/912 [============================>.] - ETA: 0s - loss: 0.9378 - accuracy: 0.7346\n",
      "Epoch 68: val_loss did not improve from 1.69392\n",
      "912/912 [==============================] - 19s 21ms/step - loss: 0.9377 - accuracy: 0.7346 - val_loss: 0.8002 - val_accuracy: 0.7749 - lr: 5.0000e-04\n",
      "Epoch 69/70\n",
      "910/912 [============================>.] - ETA: 0s - loss: 0.9380 - accuracy: 0.7333\n",
      "Epoch 69: val_loss did not improve from 1.69392\n",
      "912/912 [==============================] - 19s 21ms/step - loss: 0.9378 - accuracy: 0.7333 - val_loss: 0.7155 - val_accuracy: 0.8052 - lr: 5.0000e-04\n",
      "Epoch 70/70\n",
      "910/912 [============================>.] - ETA: 0s - loss: 0.9303 - accuracy: 0.7376\n",
      "Epoch 70: val_loss did not improve from 1.69392\n",
      "912/912 [==============================] - 19s 21ms/step - loss: 0.9301 - accuracy: 0.7379 - val_loss: 0.7315 - val_accuracy: 0.8002 - lr: 5.0000e-04\n"
     ]
    }
   ],
   "source": [
    "model, history  = train_model(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "99b4e4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_genres = {'blues':1, 'classical':2, 'country':3, 'disco':4, \n",
    "           'hiphop':5,'jazz':6, 'metal' :7, 'pop': 8 ,'reggae': 9 ,'rock':10}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9d226b1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "228/228 [==============================] - 1s 5ms/step\n",
      "(7296,) (7296,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       blues       0.71      0.74      0.73       901\n",
      "   classical       0.91      0.95      0.93       865\n",
      "     country       0.53      0.70      0.61       500\n",
      "       disco       0.85      0.91      0.88       714\n",
      "      hiphop       0.86      0.86      0.86       457\n",
      "        jazz       0.82      0.84      0.83       827\n",
      "       metal       0.94      0.83      0.88       981\n",
      "         pop       0.78      0.58      0.67       481\n",
      "      reggae       0.80      0.88      0.84       660\n",
      "        rock       0.76      0.65      0.70       910\n",
      "\n",
      "    accuracy                           0.80      7296\n",
      "   macro avg       0.80      0.79      0.79      7296\n",
      "weighted avg       0.81      0.80      0.80      7296\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_true = np.argmax(y_test, axis = 1)\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "labels = [1,2,3,4,5,6,7,8,9,10]\n",
    "target_names = dict_genres.keys()\n",
    "\n",
    "print(y_true.shape, y_pred.shape)\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4f4b11ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAScAAAEnCAYAAADrWoVBAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAABp10lEQVR4nO2ddZxU1fvH389s77JL59ISotJLh3RJiNRXAUXFQEEMwkKkFEXABDHoBmmW7kVgl1i6UZDuhmXj/P64d5YBNiZl+Hner9e8dubG5545M/vMuSeejyil0Gg0Gm/D8rALoNFoNCmhg5NGo/FKdHDSaDReiQ5OGo3GK9HBSaPReCU6OGk0Gq/E92EXwJu5NfETt8+zyPb6JHdLAuAjnvmduZ1wxyO6fj7u/+plDQx1uybA9fjbHtGNS4z3iK4nCPMP9ojuqct7JLV9uuWk0Wi8Eh2cNBqNV6KDk0aj8Up0cNJoNF6JDk4ajcYr8drgJCIFRWRXCttXi0jEv12eq7fv0GPGBp4dsYSWI5aw/fgFAKZEH+LZEUt4buRShi/fAUB8YhKfzYuh9c9LaTtqGTF/n01XPzw8N5GLprB5yzJiNi/lrbdeBiBz5ozMnz+B7TtWMX/+BDJlCrO7zOHhuVkQOYnozUvYFLOYLm91St73xpsvsnnrMjbFLKb/wN4O1MSDvPNOZ2K3rWDb1uVMGP8jAQEBTumkVgeDBn3E1m0r2LRpEVOmjiJjRvvrwEpYWCg/jx3Kyo3zWLFxLuUqlE7e99rbL3Ls4k4yZ8lkt15AgD/LVs1k7Z/z+DM6kg8/fgeAhUsms2b9PNasn8fuA1FMmDLCoXJ6qg488f2yEr1jGSvXz2HZulksXjUdgF6fdGPF+tksWzeLqbN+JWeu7A7rirdmJRCRgsACpdRT921fDfRQSm32dBlspxJ8OjeGcvmz8VzZQsQnJnErPoH9py/zW9Q+fvhfNfx9fbh44zZZQgKZGnOIPacu0b95BS7euM3bk6OY1LkuFpFUpxLkypWdXLlyEBu7mwwZQohaP5//tXudDh1ac+nSFYYOHckHH3QhU6aM9Okz+IHzU5pKkNPU3G5qro2ax/P/e4McObLRo9fbtHnuVe7cuUO27Fk5f+5CiuVKbypBnjy5WLVqFqVL1+H27dtMnjSSRYtXMmHCjDTPS2kqQWp1EB6em9Wr/yQxMZEBAz4ESLEO0ppKMOyngURv3MrUCbPw8/MlKCiIq1evkTs8J19/14/HihbimdrtuHTx8gPnpjaVICQkmBs3buLr68uipVP5qPdANsfEJu8fN/FHIhcuZ9qUOSmen9JUAlfrIDVc/X6lNZUgescyGtVqw0WbussQGsL1azcAePWNDhQr/hi93+/3wLmP8lQCXxGZJCJ7RWSmiNxTQyJy3eZ5axEZaz7PLiJ/iEiM+ahmbn9aRGLNxzYRsWtizLXb8Ww9do6WZQoC4OdjISzQn+mbj/By1eL4+/oAkCUkEIAj569RsWCO5G2hgX7sPnkpzWucPn2O2NjdAFy/foP9+w+TJ08unmlan0mTZgIwadJMmjarb0+RAThz+hzb79E8RJ48uXi1c3uGD/2ZO3eMwJNaYLIXXx9fgoIC8fHxISg4iFOnzjilk1odrFixjsTERACiY7YRHp7LId3Q0AxUrFqeqRNmARAfn8DVq9cA6DuoF1/0HYYzP9I3btwEwM/PF18/33s0QkMzUKNmZSIXLHdI01N14InvV1pYAxNAcHCQU/Xr7cGpODBCKVUCuAq8Zed53wHDlVIVgFbAb+b2HsDbSqkyQA3glj1iJy7fIHNwAJ/N20y7X5bTb/5mbt1J4OjFa2w9dp4Ov6/g1XGr2XXyIgDFcmZk9YGTJCQlceLSDfacusyZqzftftP58+eldOkniImJJUeO7Jw+fQ4wvmA5cjjePDY0wylV+kk2x8RSpGghqlatwMrVs4hcPIVy5Uo5pQlw8uRphn87isOHNnHs6FauXrnG8uVrnda7W967dWDLiy+2YenS1Q5p5SsQzsXzlxj640AiV0/nq+8+Jyg4iPqNa3P61Fn27j7gVBktFgtr1s9j/5GNrF61ni2btyfva9K0HmvXbODatetpKKSNO+sgNV13fL+UUkyd/RtLVs+gw0ttkrd/+Gl3Nu9awXNtmjLkix8c1vX24PSPUmq9+XwiUN3O8+oBP4pILDAPCBORDMB6YJiIvANkUkol2COWmJTEvlOXaRtRmGmv1yPQ35fR6/eRmKS4evsOE16pw7v1StHrj40opXi2TEFyhgXxwm8rGLI0ltL5smKRVFuv9xASEszkKSPp1at/il9sZ36BQkKCmTB5BB/2GsC1a9fx9fUhc+aM1Kn1HH0++ZKxExz/4ljJlCkjzZo2oFjxKhQoWJ6QkCBeeP45p/Ws5U2pDnr2epuEhESmTp3jkJ6vrw9PlS7BhDHTaFKrLbdu3uK93l3o+n5nhn7xk9PlTEpK4ulqzXnq8RqUK1+KEiWKJu9r1bopf8xY4LS2u+sgPV0rzny/WjTqQIOnW/NC6zfo9NrzVK5aHoDBA78j4qm6zJqxgJdfb++wrrcHp/trKq3XgTbPLUBlpVQZ8xGulLqulBoMdAaCgPUi8vj9FxSR10Vks4hs/n3lNgByhgWTIyyIkuFZAahfIpy9py+TMyyIuo+HIyKUDM+CRYRLN+/ga7HQs0EZpr9en2/bVePa7TsUyJr+HaSvry+TJ//MtKlzmDd3CQBnz54jl9mZmCtXds6dO5+uzv2aEyePYPq0ecyfZ2iePHGaeebzLVt2oJKSyJoti0O6VurWqc7ff//D+fMXSUhIYM6cRVSuUt4pLWt5768DgA4dWtO4cV1eebm7w5qnTp7h1MkzxG7ZCUDk3GWULFWCfPnDWbxuJutjF5M7T04iV08ne46sDutfvXKNqLWbqFu/JgBZsmamXEQpli5Z5bAWeKYOUtN19fsFcPqUMeBz4fxFFi1YQZn7WuKzZizgGSduF709OOUXkSrm8xeAqPv2nxGREiJiAVrabF8KdLO+EJEy5t/HlFI7lVJfATHAA8FJKfWLUipCKRXxap2yAGTLEEiusCD+Pm/0U2z66yyFs4dRu3geYv42msRHL1wjPjGJzMH+3IpP4NYdo1G24cgZfC0WHsue/ijIyJFfsX//IX744ffkbZELl9O+fWsA2rdvzcIFy9LVseWnkYPZv/8wP9loLpi/jJo1KwNQpEgh/Pz9uHD+okO6Vo79c5JKlcoSFGT8NtSuXZ19+w45pQUp10H9+k/z7ntv0LZNZ27dcnyd27mzFzh14jSFixQEoNrTldi5Yy/liteiWplGVCvTiFMnz9CkVlvOnbWv/y1rtiyEZTR+cAIDA6hVpyoHDhwBoHmLRixZvIq4OOfWJXqiDlLTdfX7FRQcREiG4OTnT9euyv69BylUuEDyMQ2b1OHQwSMOl9fbR+sWA5uB8sAeoCMQiTlaJyKtga+Ac+ZxGZRSnUQkG/ATUAJjcfNapdSbIvIDUBtIAnYDnZRScamVwXa0bt/py/RfsIX4xCTCM4XQv3kEQf6+9J23mf1nLuPnY+H9eqWoWCgHJy7f4K1J67CIkCMsiL5Ny5MnUwiQ+sLfKlUiWL5iJrt27iXJ/Ew+7/s1MTGxTJjwE3nz5eGfYyfo2PFtLl268sD5KY3WVa4SwdLl09m1ax9JSUkA9P/8G1atXM+In7+iZKkS3LkTz6cff8naNRtSLJc9C38/6/MBbdo0IyEhgdjY3bzxZs/kzvbUSGm0LrU6GPLN5wQE+CePBkVHb6P7O588cH5ao3VPPFWcr7/rh5+/H8f+Pk6Prn24cuVq8v71sYtpWud/do/WPfFkcUaM+hofHwsWi4U5sxYx5KsfAZgXOZHvho1ixfJ1adZBSqN1rtZBarj6/UpttC5/gbyMnvQ9YAyMzJ65kO+GjuK38d/yWJFCJKkkjv9zkt7v9UtuYdmS1mid1wYnb0BnJdBZCUBnJQCdlUCj0WiS0cFJo9F4JTo4aTQar0QHJ41G45Xo4KTRaLwSHZw0Go1XooOTRqPxSvQ8pzQICMzn9sq5fnyNuyUBCMtX2yO68Yl2LT/0CgJ8/TyieyfBM/ORxM71lo6S5IH/aR+LZ9oxcbf/0fOcNBrNo4UOThqNxivRwUmj0XglOjhpNBqvRAcnjUbjlfyrwUlEPheRHm7U+/PfLseoUd/wz7FtbN1yNzd05syZiFw4id271hK5cBKZMmW0S2v81Nm0aP8Gz3Z4k559BxMXd4fen39F0/915tkOb/LpF8OITzBGy5RSfDF8JI3bvkLLF7uwZ799OZN+/nkIR49uYfPmpcnbSpYswerVs4mJWcLMmb8TGprBgRp4kIYNarF711r27YmiV8+3XdKyEhAQwIb1C9iyeRnbY1fS97MPnNbypPOIlYwZw5g69Rd27lzDjh2rqVzJ+YR7VooVK0xM9JLkx/lze+nW7VWXdfPmzcPypTPYsX0V22NX0q2r85op/T98+cUn7Ni+is0xS5k+7Ven3HLgEW85KaWq/tvXnDBhBs2ad7xnW88eb7Fy1XqefKomK1etp2eP9FOdnzl3nkkz5zJt9PfMmfgzSUlJLFq+hmca1Gb+lF+ZPWEkcXF3+GP+YgDWbYjh2PGTRE77nc97vcOAb360u7wtWrx0z7aRI7/i008HU6FCQ+bNW8J7771h57t/EIvFwvffDaJpsw6ULF2bdu2evSddrbPExcVRr0FbykfUp3xEAxo2qEWliuWc0kpMTODjjwYSUb4+tWu15PU3OvL440X44IMurF79J6VL1Wb16j/54AN7U9Q/yPBh/Vm6ZBUlSz5N+fL12bvvoNNaVg4cOEKFig2pULEhlSo35ubNW8ydu9hl3YSEBHr26kep0rWpVr0ZXbp0cvozS+n/YcXKdZQtV4+ICg04ePCI0z9YHg1OIvKiiOwQke0iMuG+fa+ZzijbTaeUYHN7GxHZZW5fa257UkSiTdeUHSJS1Nxu677SW0R2mucNTusarhAVtYlLly7fs61ZswZMnGg4WEycOJPmzRvapZWQmEhc3B0SEhK5dTuO7NmyULNqRUTESP1bojhnzhppU1dFbaR5o7qICKWfKsG1a9c5Z0f2yvXro++x7AEj+2VU1CYAVq5cx7PPNrarvClRsUJZDh/+m7/+OkZ8fDzTp8+leTP73n963Otu4udUfmvwvPNIWFgo1atXYvSYKQDEx8ffk8jOHdSpU50jR45y7NgJl7VOnz7LtljDEvL69Rvs23eQ8DyOublYSen/YfnytclOMZuitxGeN7dT2h4LTiLyJPApUEcpVRq4P/HxLKVUBXPfXsDatvwMaGhub25uexP4znRNiQCO33etxkALoJJ53tfpXMOt5MiRjdOnjSx/p0+fJUeObOmekzN7Njo934p6z71I7RYvEBoSTDWbW4H4hATmL1lB9UqGf+iZcxfIZaObM0c2zjiR7xlg796DNGvWAIDnnnuGvE5+eQDyhOfin+Mnk18fP3GKPE5+0e/HYrGwOWYpp07sYMWKtUTHbHNZ0xPONoUK5ef8+Qv8/ttwYqKXMOrnIQQHB7lcVlvatmnOtOlz3aoJUKBAXsqUfopN0a7XbUp0eqktS5zMpe7JllMdYIZS6jyAUur+n/mnRGSdiOwE2gNPmtvXA2NF5DXAx9y2AfhYRHoDBZRS91s61QPGKKVu3net1K7hUez5hb9y9Rqr1m1kyYwxrJw7iVu345i/ZGXy/oHf/ET50k9RvsxTaag4xxtv9OT11zuyfv0CMmQI4c4d78zImJSURESFBhQoFEGFiLI8+WRxl/Q84TwC4OvjQ9myJRk1ajwVKjbkxo2b9OrV1aWy2uLn50fTpg344w/n3VxSIiQkmOnTfuX9Hn1dsrBKjd69u5GQkMiUKbOdOv9h9jmNBboqpUoC/TDdU5RSb2K0uPIBW0Qkq1JqMkYr6hYQKSJ1XLlGWti6ryQm2veBnT17nly5DBPNXLlycM4Ok8qNm2MJz5OTLJkz4efrS92nqxK7cw8AI0ZP4tLlK/R65/Xk43Nmz8rps3dbSmfOnidn9vRbaClx4MBhmjXrSLVqTZk+fR5//XXUKR0wnFzy5c2T/DpveG5OnjzttF5KXLlyldVr1tOwQS2nNTzlPAJGa/H48VPJLbs/Zi2kbJmSTpf1fho1qs222J2cPetc+VLC19eXGdN+ZcqU2cyZs8htulY6dmxDk8Z1ealTt/QPTgVPBqeVQBsRyQogIvd7D4UCp0TED6NVg3ncY0qpTUqpzzCMC/KJSGHgiFLqe2AucL8L5DLgZZt+K+u1UrxGWti6r/j42DeKtWDBMjp0MBwsOnRozfz5S9M5A3LnzM6OXfu4dfs2Sik2bY6lcIF8zJy3mPWbtvB1v95YbNYz1apemXmLV6CUYvuuvWTIEEJ2J+2csmc37I9EhA8/7Mavvzqf1zxmcyxFihSiYMF8+Pn50bZtC+YvSP/9p0e2bFmSR3kCAwOpV7cm+/cfdlrPE84jVs6cOcfx4ycpVuwxwOgf2rvXOaPOlGjXtgXTprn3lu7XX4ayd98hvv3uF7fqAjSoX4sP3n+TVq1fcdopBjy88FdEXgJ6AonANuBv4LpS6hsR6QL0wghAm4BQ0zllFlAUEGAF8C7QG8N5JR44DbyglLooIteVUhnMa30IvAjcASKVUh+ncY3PreVIq/wpLfwdP/5HataoTLZsWThz5jwDBg5l3rwlTJ40knz5wjl27DgvtH/rgU5CK7YLf3/8bQJLVqzFx8eHx4s9Rv8Pu1OhXkty58xBSLDRd1/v6ap0eaU9SikGDRtB1MbNBAUGMuDj93iqRLFkrdQW/o4b9z01alQhW7bMnD17ngEDhpMhQzBvvPEiAHPnLqZPn69SrQN7Fv42blSHoUP74WOxMHbcNL4c/H2656RHyZIlGP37t8nuJjNnzmfgoG/TPCe1hb+uOo/Ys/C3dOknGfXzEPz9/Tjy1zE6d36fy5cf1LLFnoW/wcFBHD4UTfHHqyZbqKdHegt/q1WtwJrVc9ixcw9JScaxffoMZtHilamek9rC35T+H3r17Ip/gD8XL1wCIDp6K127fZzi+Wkt/NVZCdJAZyXQWQlAZyUAnZVAo9FoktHBSaPReCU6OGk0Gq9EByeNRuOV6OCk0Wi8Eh2cNBqNV+L7sAvgzYT4pTuh3GGC8tRwuybA9CxPe0T3+cvrPKKblJTkds04Tw35e0QVCoa5Zw3i/Zy8kf4KBUeJyPKY2zXTQ7ecNBqNV6KDk0aj8Up0cNJoNF6JDk4ajcYr0cFJo9F4JTo4aTQar+T/zVQCEXkX+MWaDdNTBAT4s2DxZAIC/PH19WXenMUM/uJ7Fi6ZTIYMRv6nbNmzsHXLDjo+71zC/Lx58zB29HfkyJkNpRS//TaJH378Pf0TAUuAHzXnfIbF3xeLrw8nFmxi75A/KP/dG2SrUoL4q0b1bOk+iiu7j5LvuWoU69oMBBKu3ya292iu7DmW5jVGjfqGJo3rcu7cBcqVrwcYjhvPPFOPO3fiOXLkKK+9/oHLebQzZgxj1KhvePLJ4iileP21D9i4aYtLmq7UbXpYLBY2bVzEiROnebblS+mfkAqd3niBNh1aoBQc2HuID9/pxxff9uGpMk+QEJ/Ajm27+eyDQSQkJNqtGR6em19/G0qOHMb7HjN6CiNGjE3e3+2dznw5+BMK5CvHBTPVSWr0+qYHVepV4vL5y7xc7zUAXunRiWoNq6KSkrh0/jKD3x/ChTMXaPdmW+q3NHJD+vj4kL9ofp4t3Zprl9NP//L/JmWKiPwNRFjTAt+3z0cpZf8naZIltGiKlRMSEsyNGzfx9fVl0dKpfNR7IJtjYpP3j5v4I5ELlzNtypwHzr0al37szJUrB7lz5WBb7C4yZAghetNiWrV+hb17U3f0sJ3n5BMcQOLNOMTXh6fn9WX7p+Mp/FJdTi3bxskF0fe+x4iiXDt4kvgrN8hZpzQlerRidZPPkvenNM+pevVKXL9+g9G/f5scnOrVq8mqVetJTExk0MCPAPjk0y9TLa8985xG//4tUVGbGD1mCn5+fgQHB6UZ8Oz5JjtTt/bOc3q3++uUK1+KsNBQu4JToYwP5m7PmSs7kxf8RpPqbYm7Hce3v33JmuXruXj+EmuWrwdg2KhBxGzYypSxf6Som9I8p5y5spMrVw62x+4mQ4YQ1q2fz/PtXmffvkOEh+fmpxGDKVb8MWpUa5ZicLKd51SqUklu3bjFx9/2Tg5OwRmCuXnd+G4/98qzFCxagGEffXePRpV6lWnzWiveb9czedvq48u9I2XK/W4sIlJQRFaa21aISH7zuLEi0trmvOvm31oislpEZorIPhGZJAbvAHmAVSKyynqOiAwVke3AJyIyx0avvog4l9iY+11BfO/JPR0amoEaNSsTuWB5aqeni6vuGIk34wCw+Plg8fWBNH6ALm4+SPyVG8bzLYcIyp1+dk1POm5Y8ZSjiTudR2wJD89N48Z1GT16istavr4+BAYG4OPjQ1BQIGdPn0sOTAA7tu4mV56cDmmeOX2O7fc40Bwit/m+v/q6D59+OtjuHOo7Nu18oOVjDUwAgUFBKX7l6j5bhxVz7Tc7+NeCUypuLD8A45RSpYBJgD0pFMtiZMd8AigMVDPT954EaiulrFnXQoBN5rUGAI+LiNVe42VgtLPvxWKxsGb9PPYf2cjqVevZsnl78r4mTeuxds0GtyWMd8odwyLUWf4Fz+z6mTNrd3Jpm5He9skP21J35WBK9uuAxf/BO/qCL9TizMrtD2x3FFccN6z8G44m7nQeGTq0Hx99NNDlme9nTp/j9xETWR27gPW7FnPt6nXWr96UvN/X14cWbZuwbqVTfrIA5M8fTunST7A5JpZnmtbn5MnT7Nq516VyA7za62WmR0+mfss6jP5m7D37AgIDqFgrgrWR9q84+DdbTim5sVQBJpv7JwDV7dCJVkodV0olAbFAwVSOSwT+MK+lTP0OIpLJvG6KWd1tDQ7i4lNOs5qUlMTT1Zrz1OM1KFe+1D2GhK1aN+WPGe5xyXDaHSNJsbLexywq25UsZR8j7PG87B40jWXVe7Cq0af4Z85g9DPZkK3aExR4vha7Brr2y++q44YVTzuauNN5pEmTepw7e56t23a6XK6wjKHUbfQ0dco3p3rJRgQHB9G89V1fwc+//pCYDVvZvDHWKf2QkGAmTRlJ714DSEhIoEfPtxg4YLjL5Qb4/esxtK34Astmr6Tlyy3u2Ve1fhV2xey2q6/JireO1iVglk1ELIC/zb44m+eJpN6pf/u+fqYxQAfgeYwgmWL+WVuDgwC/tG3Fr165RtTaTdStXxOALFkzUy6iFEtdbDWAe9wx4q/e5Nz6PeSsXZrbZy8DkHQngaNT15C57N0+hLAS+Sg39DU2dhrKnUvO/6O6w3HDiicdTdztPFK1agRNmzbg4IGNTJo4gtq1qzFurHN51Ks+XZHjx05y6cJlEhISWbpwFWUrGH4eXXu8Rpasmfmyj3PBxNfXl0mTRzJt6lzmzV1C4cIFKFggLxs2RbJ77zrCw3MR9ed8cuR0ztXHyvLZK3i68b1rSOu0qOXQLR38u8EpJTeWP4H/mfvbA9Y239+A1WGyOWBPcuhrGG4rKaKUOolx6/cpRqByiqzZshCW0bhMYGAAtepU5cCBI0ZBWzRiyeJVxMXdcVY+GWfdMfyzhuIXZpgjWAL9yFGzJNcOnSQwR6bkY/I0iuDqPsOXNCg8K5VHv8fmriO4fsR5Syd3OW5Y8aSjibudRz79dDCFCkdQtFhl2nd4i1Wr1vNSp3ec0jp5/DRlyj9FYFAAAFVqVuDIwb9p06EF1WtX5r03PnHaX2+E6UDzo+lAs3v3fgoVrMCTJWrwZIkanDhxmupVm3H2jOMWVOGFwpOfV2tYlWOH/0l+HRIaQunKpVi/xLFb0X9tKoFSareIDALWiIjVjaUbMEZEemI4pLxsHv4rMNfszF4M3LDjEr8Ai0XkpE2/0/1MArIrpZy+wc6ZMzsjRn2d7AoyZ9Yili42fhGea/0M3w0b5ax0MtWqVqBjh9bs2LmHzTGGzVJ67hhWAnNkIuL7LoiPBSzCiXkbOb1sG9VnfkJA1lAQ4cquo2zrZXxBS7z/HP6ZQykz2Kh6lZjEqoafpnkNW8eNw4ei73HciFxo3KWn5bhhL+++14fx4364x9HEVVyp23+DHVt3s2T+CuasmERCQiJ7d+5n6vhZbD+6jpP/nGb6IqOrdOmCVfw09De7datUieCF9s+xa+c+/ty4EIDP+w5h6ZLVDpexz48fU6ZKaTJmyciMmCmMGTqOSnUqkb9wXpKU4szxMwz76Nvk42s0qsbmNVu47eCP1v+bqQT2ICI/AtuUUnZNbEltKoEr2DOVwBl0yhT7phI4g6dSpqQ0lcAdPEopU9KaSvD/ZhJmeojIFowW2AcPuywajSZ9/jPBSSlVPv2jNBqNt+Cto3UajeY/jg5OGo3GK9HBSaPReCU6OGk0Gq/kPzWVwFEyZyji9sq5dueWuyUBsIhnBrwvf9fKI7oZ35npdk2L5dH6rfXU/55F3F8P/j6eGTu7euOId2Ql0Gg0GnvRwUmj0XglOjhpNBqvRAcnjUbjlejgpNFovJJHJjiJyOci0kNE+otIvYdVjoAAf5av/oN1G+bzZ8wiPvykOwDf//Ql6zbMJ2rjAsZO/JGQkGCXrtOwQS1271rLvj1R9Or5tjuKTteur7Jt63Jit62gW7dXHT7/2u14eszfRsux63hu3Dq2n7yba3r8lr8oO3wxl24Z6WLGbf6LdhPX027ielqPj6L8t4u5ctvxVDIWi4WY6CXMmT3O4XOtjBr1Df8c28bWLXdTJz/33DNs27qcWzePUq5cKbfpZs6ciciFk9i9ay2RCyeRKVPaOcHSw9XP7G5Zh3Ds2Fa2bFmWvK1v3w+IiVnCpk2LWLBgIrlzO5b6F4z0xAsiJxG9eQmbYhbT5a1OAJQsVYIVq/4gasMCVq+bS/nyjtfxIxOcrCilPlNKOZ+g20Xi4u7Q4pmO1KjSjJpVmlG3Xg0iKpThkw8HUaNKM6pXbsrxf07y2hsdnb6GxWLh++8G0bRZB0qWrk27ds/ek23TGZ58ojivvvI8Vas1pXxEA5o0qcdjjxV0SOPr1XupWjAbszvVYFqHahTOYrjNnL52i41Hz5MrNDD52JciCjGtQzWmdahGt2rFKJ83CxkD/VOTTpV3unVm777UzQfsYcKEGTRrfu/nsWf3ftq1e511UZtSOcs53Z493mLlqvU8+VRNVq5aT88ezjnwgHs+M9uyNm/+4j3bhg0bRYUKDalUqTGRkSv4+OPuDusmJCbwycdfUDGiIXVrt+K11ztS/PEiDBj4IYO//J7qVZryxcDh9B/4ocPaqQYnEdlpGg/c/9gpIjscvpITiMgnInJARKKA4ua2ZPMDERksInvMcn1jbsspIrNNE4XtIlLV3P6+iOwyH++6Ui5bgwM/Pz+UUvekeg0KCnBpDkvFCmU5fPhv/vrrGPHx8UyfPpfmzRq6UmQef7wI0dGx3Lp1m8TERNat3cizzzZO/0STa3HxbD1xiZZP5QXAz8dCaKCRA/Cb1fvoXqM4qU21Wrz/FI2KO54exF2mASkZMuzbf4gDB4+4XbdZswZMnGjM4Zo4cSbNmzv/ubn6md1b1ugHymr7nQ0JCXbqO5uScUKePLlQShEaavx4hYWFcvr0WYe105pZ1dRhNTciIuUxsmSWwSjnVmCLzf6sQEvgcaWUMnODg2GSsEYp1VJEfIAMptbLQCWM9DybRGSNUsqpzPYWi4XVUXMoVLgAv/8yMdng4MeRg6nfsBb79x3i049St0VKjzzhufjn+Mnk18dPnKJihbJO6wHs3rOf/v17kyVLJm7duk2jRnXYstX+35iTV26ROcifvkt3cuDcNUrkzEivWo+z8dgFcmQIpHj2sBTPuxWfyJ9/n+fDOiUcLrPVNCCD+SV/FMiRI1vyP+Lp02fJkcP5lLeufmb20K9fT9q3b8WVK9do2LCdS1r584dTqvSTbI6JpXevAcyeO46BX3yExWKhfp3W6QvcR6otJ6XUUevD3FTUfH4WuOhc8R2iBjBbKXVTKXUVmHff/ivAbeB3EXkOsGZxqwOMBFBKJSqlrmAYJ8xWSt1QSl0HZpn6TpGUlETNqs15snh1ykWUpsQTxi1X1y4fUqJIVQ7sP0zLVs84K+8R9u07xJBvRhC5cDIL5k9k+47dyVZO9pCQpNh39iptSuVnaodqBPn68POGQ4yOPkKXqkVSPW/tkbOUyZPJ4Vs6d5oGPExcaUG7+pnZQ9++QyhSpDJTp86hS5dOTuuEhAQzYfIIPuw1gGvXrtO5c3s+6j2QJ4pX56PeA/lx5FcOa6bb5yQirwEzAWv+2bzAHIev5GZMg4KKGGVripHO12XudV9J2yft6pVrrFu7kbr1aiZvS0pKYtbMBTRv4Xxz/uSJ0+TLmyf5dd7w3Jw86Xx+bytjx06lcpUm1K3XmsuXrnDQgduanKGB5AgNoGTuTADUK5qTfWevcuLKLdpNXE+T31dz9locL0z6k/M37npQLNl/ikaPO35L507TgH+Ts2fPkytXDsAw8Dx3zrWslK58Zo4wdepsp28ZfX19mTh5BNOnzWP+vCUAPN++FfPmGv+Ss2dFeqxD/G2gGnAVQCl1EMjh8JUcZy3wrIgEiUgocI+XkYhkADIqpSKB94DS5q4VQBfzGB8RyYhhnPCsiASLSAjG7WCK+WfvdV958FblfoOD2nWqcejgXxQqXCD5mEZN6iabHjhDzOZYihQpRMGC+fDz86Nt2xbMX7DUaT0r2bNnBSBfvjw8+2xjpk6dY/e52UICyJUhiL8vGv0U0f9c4PEcYax8sw6Rr9Yi8tVa5AgNYHL7qmQLMZLzX4uLZ8vxS9R6zPGviztNA/5NFixYRocOxi1Mhw6tmT/ftc/Nlc8sPWw715s2bcD+/Yed0vlp5GD27z/MTz/czX59+tQZqteoBMDTtapy+PDfDuvas5ovTil1R8zeThHxxXPpmpNRSm0VkWnAdoxbyZj7DgnFMEEIxOhHsma/7w78IiKvYlhHdVFKbRCRsYDVi/s3Z/ubcuXMzohfhiQbHMyeFcmSxatYtHQqoWEZEBF27dzLB+/2dUYegMTERLq/+ymRCyfjY7Ewdtw09uxx3Xlk2tRfyJo1M/HxCbzT/ROHHXR71y7Bx4t2kJCURHjGYPo1SNuqadWhM1QukJUgv4ebcDUlQ4aLF68wfFh/smfPwpzZY9mxYw9Nm3VwWXfINz8xedJIXu70P44dO84L7Z0frQPXP7O7Zf2BGjWqkC1bZg4d2sTAgcNo2LA2xYo9RlJSEseOnaBbt48c1q1cJYLnX3iOXbv2EbXB8Gvs//k3dOv6MV8N6YOvry9xt+Po3vUTh7XTzUogIl8Dl4EXMdxS3gL2KKUcv9ojhs5KoLMSeBKdlcD1rAQfYtg27QTeACIxvN80Go3GY6QbDpVSSSIyDtiEcTu3X+kkUBqNxsOkG5xE5BngZ+AwRt9OIRF5Qynluo+zRqPRpII9N5JDgdpKqUMAIvIYsBDQwUmj0XgMe/qcrlkDk8kR4JqHyqPRaDRAGi0nc9Y1wGYRiQSmY/Q5teHBYX2NRqNxK2nd1tlOejwDPG0+PwcEeaxEGo1Gg3ZfSZOgoAJur5z4xAR3Sz6SrMpSxe2atS9ucLsmGKNAnsDf188juncS4t2u6WPxcbsmwO3bx1KtXntG6wKBV4EngeSEPUqpV9xSOo1Go0kBezrEJwC5gIbAGoyFv7pDXKPReBR7glMRpVQf4IZSahzwDEZeJI1Go/EY9gQn6w3sZRF5CsjIv5OVQKPR/IexZxLmLyKSGeiDkfAtA/CZR0ul0Wj+86TbclJK/aaUuqSUWqOUKqyUyqGU+tnVC4tIQRHZlcL2dN1VbPOI/9v8/PMQjh7dwubNd/P0lCr1BGvWzGbjxkiiouYTEVE6DYX0+fWXoZw8vp3YbStcLe6/ouuKU4wE+FFm0ZeUXfEN5dYMJ3/PtgBkrPYUZZd+TbnVwyj2fVfwMb6qQUXyUHrBIKodnUJ4l+YOl9VTdQDucYoJD89N5KIpbN6yjJjNS3nrrZcByJw5I/PnT2D7jlXMnz+BTJlSTotsLxkzhjF16i/s3LmGHTtWU7lSead0POXqAmlMJRCR91PcYaKUGubUFe/qFwQWKKWecuLcsea57s+7YUNKUwmqVavIjRs3+e23YURENABg/vwJ/PDD7yxdupqGDWvz/vtv0LDh/1LUtGcqQY3qlbh+/QZjxnxHmbJ1XXwXntW1WCzs3b2ORk2e5/jxU2zcEEmHjm+xd2/ajim2UwkswYEk3byN+PpQat5Ajnw2lhKj3mNnm37cOnKKAr3acfufc5yZshK/bGEE5M1O1kYVSbhygxMj72ZvtmcqgTN1YO9Ugne7v0658qUICw3l2ZYvpXt8SlMJcuXKTq5cOYiN3U2GDCFErZ/P/9q9TocOrbl06QpDh47kgw+6kClTRvr0GZyirj1TCUb//i1RUZsYPWYKfn5+BAcHpZkrKrWpBNWrV+T69Zv8/vtwypevD0BoaIZk84S33nqZEiWK0q3bxymen9ZUgrRaTqHpPNyBj4j8KiK7RWSpmfXS1l3lbxH52nR8iRYR22TVNUXkTxE5YnO8iMgQ02Flp4i0M7fXEpG1IrJQRPaLyM8iziW9Wb8+mosXL9+zTSlFWJiRhD9jxlBOnXLcacKWdVGbuHifU4Y78ISuO5xikm7eBkD8fLD4+kBiEknxCdw6cgqAS2t2kK1pZQDiz1/leuxhVIJzubQ9Vbfucoo5ffocsfe4mRwmT55cPNO0PpMmGb/FkybNpGmz+k5fIywslOrVKzF6jFHW+Ph4p5PYecrVBdLoc1JK9XNK0TGKAs8rpV4TkelASpnNriilSorIi8C33HWFyY1hXPA4Rl/YTOA5DLeW0kA2IEZE1prHVwSeAI5i5Bt/zjzHZXr27M/8+eP58stPsFgs1K79XPon/T/BLU4xFgtll35FUKFcnByzhGvbDiK+PmQo/RjXtx8mW9PKBOTJ6uaSuxdPOMXkz5+X0qWfICYmlhw5snP69DnACGA5cmR3WrdQofycP3+B338bTqlST7B16w7ee/8zbt50XyJEd7i6POzUgX8ppWLN51uAgikcM8Xmr+204jlKqSSl1B7AelNbHZhiuq6cwZiXVcHcF62UOqKUSjS1qrvrTbz+egd69RpA0aJV6NWrPyNHfu0u6f8GSUlsq9eTTWXfILRsEYIfz8e+N4ZTuF8nyiz6ksTrt1CJSQ+7lKniCaeYkJBgJk8ZSa9e/e9piVhxZWWHr48PZcuWZNSo8VSo2JAbN27Sq1dXV4r7AO5wdXnYwSnO5nkiKbfkVCrPbc+1p1vg/k8zxU/X1n0lIeHBL0VKtG/fijlzjAwyf/yx0OUO8UcJdzrFJF69yZX1u8hcuyzXthxgx7N9iG38EVc27k2+xfNG3O0U4+vry+TJPzNt6hzmzTXcTM6ePUeuXEZrKVeu7Jw7d95p/eMnTnH8+CmiY4w0+n/MWkjZMmnng3cWV1xdHnZwsod2Nn/T6/FcB7QzXVeyAzW5a2pQUUQKmX1N7YColARs3Vd8fe1rop86dZYaNYw+kVq1qnHo0N92nff/AVedYvyyhuETFgyAJdCfTDVLc+vQCfyyGaNR4u9Lvq7Pcmqc6+4znsLdTjEjR37F/v2H+MHGzSRy4XLatzcGqNu3b83CBctSOz1dzpw5x/HjJylW7DEA6tSpzt69rhtoWHGXq0taKVM8OlrnAJlN+/M44Pl0jp2Nceu3HaNl1EspdVpEHsdI8/IjUARYZR7rMOPGfW/jYrGRAQOG8/bbvRky5HN8fX2Ii4uja1fHfeFtmTjhJ56uWYVs2bLw95HN9Ov/DWPGTnVJ01O6rjrF+OXITPHvuyI+FrAI5+f9ycVlWyj0WUey1CsPFuHUuKVcWW/MOvHLnomyS77CJzQIkhThrz3Dlprvknjdvv4ST9Wtu6hSJYIX2rdi1869bNgYCcDnfb9m6NCRTJjwEy++1JZ/jp2gY0fHpmzcz7vv9WH8uB/w9/fjyF/H6Nw5zX/3VPGUqwukPZXA6m1UHKPfxjpm2wyj/8YxHx1nCifyNxChlHK+DWvo1AJ6KKUcsljXWQk8h85KoLMSgJNZCayjdeZoVzml1DXz9ecYaXo1Go3GY9izfCUncMfm9R3ujo55FKVUQTfprAZWu0NLo9H8O9gTnMYD0SJi7aN5FnB+fr5Go9HYgT2+dYNEZBFQw9z0srNW3hqNRmMv9k4lCAauKqW+A46LSCEPlkmj0WjSD07mqF1vwDoe6AdM9GShNBqNxp6WU0ugOXADQCl1Evct/NVoNJoUsadD/I5SSomIAhCREA+XyWvIEui+RZxWLsfdcLsmQEKSc6v00yMpyTNr2up4YE7StZnvuV0TIKz1cI/o+lvs+fdznDu4f55Tkvr31zba03KaLiKjgEwi8hqwHPjNs8XSaDT/dewZrftGROoDVzFmi3+mlHJ+YY9Go9HYgT2+dV8ppXoDy1LYptFoNB7Bntu6lFLuOZcDQaPRaOwkrawEXYC3gMfMrABWQoE/PV0wjUbz3yat27rJwCLgS8A2B8g1pdRFj5bKDkTkT6VU1Ydx7Y3bl3L9+g2SEpNISEigSZ12vN/7LV54sTUXL1wCYPCAb1m5bJ3dmuHhufn1t2HkyJENpRRjRk9hxIgxDBr0EY2b1CP+zh2O/HWMN9/o6VC+51GjvqFJ47qcO3eBcuUNU5svv/iEZ56px5078Rw5cpTXXv/A6RzSViwWC5s2LuLEidN2Jfe3h4MHNnL9+nUSzXquXKWJ3edevRVH/xnrOHT6IiLC521qEujvy6A/orh5J548mUP54oXaZAj0Jz4xiX4z1rLvxHkSkxRNyxfl1TplHC6vO+ogIMCfhUumEBDgj4+vL/PmLGbwoO/46eevqFa9IlevGmbbb73Rm1079zp1DXeW937eeaczr7z8PEopdu3aR+fXPiAuLi79E1MqX2o7lFJXlFJ/A98BF5VSR5VSR4EEEXnojr8PKzBZadPsZRrUbEWTOnfzI/86cjwNaraiQc1WDgUmgMTEBD7+aCAR5etTu1ZLXn+jI48/XoSVK6OoENGASpUac+jgX/To8ZZDuhMmzKBZ8473bFuxch1ly9UjokIDDh484rCdU0q8060ze/el7bjiDPXqtyGiQgOHAhPA13M3ULV4Xub0asv0956jUM5M9JuxlneaVGTmB62p81RBxq02bgiW7ThCfEIiMz9ozeTuLZm5cS8nLl5zuKzuqIO4uDu0eKYjNao0o2aVZtStV4OICmUA+OzTr6hZtTk1qzZ3OTC5q7y25MmTi7fffoXKVZ6hbLl6+Pj40Lat4/ZdVuzpcxoJ2OarvW5ue6iIyHURySAiK0Rkq+m20sLc96aIxJqPv0RklYg0t9m2X0T+etjvwZbUXDdWrFhHYqIxhyk6Zhvh4bkc0o2K2vSAO8by5WuTNTdFbyM8b26Xyu4u5xF3ce3WHbYeOUXLisUB8PP1ISwogGPnr1C+sFF/lYuFs2Kn8RUQ4NadBBISk4iLT8DPx0KGQMdyLbmzDm7cuGmU288XPz8/l/KFp4anPjNfH1+CggLx8fEhKDiIU6fOOK1lT3ASZVM7Sqkk7Ju8+W9wG2iplCoH1AaGiogopX5WSpXBSJJ3HBimlJqnlCpjbt8OfOPsRZVSTJn1K4tWTaf9S22St7/82gssi5rF0B8GkDGj86aHtq4btrz4YhuWLl3ttG5KdHqpLUuWrHJJw+o84u4Jm0opFkVOYdPGRXR+tb3d5524eI3MGYL4bNoa2g2fRb8Za7l1J57COTOzavdRAJZtP8LpK8aE2HqlChPk70v9AZNoNGgKLz5diozBgQ6V1Z11YLFYWPvnPA78tYnVK6PYsnk7AJ9+9j5RGxcwaPAn+Pv7u3QNT3xmJ0+eZvi3ozh8aBPHjm7l6pVrLF++Nv0TU8Ge4HRERN4RET/z0R044vQV3YsAX5gd9suBcO7NNfUdsFIpNT/5BJFewC2l1E/OXrRl4440qtWGDm3epFPn56lUtTzjR0+jatlGNKjRirNnzvHZwJ5OaafmutGz19skJCQydeocZ4v9AL17dyMhIZEpU5zKWAx4xnnESq3aLalYqRFNm3WgS5dOVK9uX29CYlIS+06cp23VJ5j23nME+vsyeuV2+rV9mul/7uH5b2dzIy4eP9NFeNexs1gswtI+7Yn8+H9MWLuT4xfs74Nzdx0kJSVRs2pznixenXIRpSnxRFH69/2GiuUaUKfmc2TOnJHu77/utL6nPrNMmTLSrGkDihWvQoGC5QkJCeKF5523SbMnOL0JVAVOYLRCKgHO14x7aQ9kB8qbLaIzQCCAiHQCCgDJ/numzXkbjPeUIrbuKzfiLqV4zGnTNPPC+YssWrCcMuVKcv7cBZKSklBKMWncTMqUd9zNIiXXDYAOHVrTuHFdXnm5u8OaqdGxYxuaNK7LS526uaTjbucRW6wuLufOXWDO3EVUMPte0iNnxhByZAyhZP4cANQvWYi9J85TKEcmfn69CVPebUnjso+RN6vRul207TDViufDz8dClgxBlCmYk93Hz9ldTk/VwdUr11i3diN169XkzBmjPHfu3GHSxD8oX76U07qeKm/dOtX5++9/OH/+IgkJCcyZs4jKVZyzOQc7gpNS6qxS6n9KqRxKqZxKqReUUq5Z2rqPjMBZpVS8iNTGCEaISHmgB9DBvA1FRAoAPwFtlFKpZsO3dV8JCcj8wP6g4CBCMgQnP3+6TlX27z1EjpzZko9p3LQe+9Ox406JlFw36td/mnffe4O2bTpz69ZthzVTokH9Wnzw/pu0av2Ky5rudh6xEhwcRIYMIcnP69d7mt2799t1brawYHJlCuHvs5cB2HToJIVzZuaiaYKQlKT4dfk22lQuAUDuzCFEHzKMQW/diWfn0bMUyp7J7rK6sw6yZstCWEZjXX1gYAC161Tj4IEj5Mx510Tzmab12LvH+Y5sT31mx/45SaVKZQkKMm6Ja9euzr59h5zWS2ueUy+l1Nci8gMpeLwppVx/N66hgEnAfBHZCWwG9pn7ugJZgFUigrnvHyArMMfcdlIp5dgQEJA9e1Z+n2j8yvj4+DDnj4WsXhHF9z9/yRMlH0cpxfFjJ+n93ucO6abmujHkm88JCPBn/gIjS0109Da6v/OJ3brjx/9IzRqVyZYtC4cPRTNg4FB69eyKf4A/kQsnm5pb6ZqKl/3DImfO7MycYQRpH18fpk6d41B/W+8W1fh4yiriE5IIzxpK/7ZPM3/LQab9aQw61C1ZiBYVigHQruqTfDZ9Dc99MwMUNK9QjGIPyWE4V87sjPhlCD4+FiwWC7NnRbJk8SrmLpxAtmxZEBF27tjL+937PJTypUVMzDZmzYoketNiEhISiI3dzW+/TXJaLy33lWZKqfkikuIECKXUQ0vVKyJZga1KqQKevE545ifdPkyisxJ4jquPWFaCDP5BHtG9fsd9tuJWzB90t3Mn7rhT7ivzzb9elS9cRPJgmBU4Pdqm0Wi8n7Ru6+aTimU3gFLK+dlVLmAmuyv2MK6t0Wj+PdKar2RtmTwH5OJuat7nMUbFNBqNxmOkdVu3BkBEhiqlImx2zReRzR4vmUaj+U9jzzynEBEpbH1hOq/8Z1L1ajSah4M9y1DeA1aLyBGMGdkFgDc8WiqNRvOfJ9WpBPccJBIAPG6+3KeUci4HwiOGn3+426cSuH8Jp2fxtfh4RNdTUx88wa1/VnpENyhfHY/oeoJQD017uHT9UKpTCezxrQsGegJdlVLbgfwi0tSN5dNoNJoHsKfPaQxwB6hivj4BDPRYiTQajQb7gtNjSqmvwTDDUkrdxOh70mg0Go9hT3C6IyJBmN0lIvIY8J/oc9JoNA8Pe0br+gKLgXwiMgmoBnTyZKE0Go0mzeAkIhYgM8Ys8coYt3PdlVLn/4WyaTSa/zBp3taZuZB6KaUuKKUWKqUWeHNgEpEyIpJuGhQRqSUiC9xxzYMHNrJt63I2xyxl44ZId0gC0LBBLXbvWsu+PVFuMSDImzcPy5fOYMf2VWyPXUm3rq86rTVq1BCOHdvKli13jZ/79v2AmJglbNq0iAULJpI7d840FOzD3XUArtfD+OlzafHi2zz7Uld69htCXNwdJv+xgMbPv85TNZtz6fLdDJpHjh6nfZeelK37HGOczDbqiTpwp25AgD/LV//Bug3z+TNmER9+YiRE/P6nL1m3YT5RGxcwduKPhIQEO6yd7jwnERkMnAemAcn5PrzBHup+zOyXEUqprukcVwvooZRKc0qEPfOcDh7YSOUqjblwIeWsmfdjzzwni8XC3t3raNTkeY4fP8XGDZF06PgWe51IYGclV64c5M6Vg22xu8iQIYToTYtp1fqVdDVTmudUvXpFrl+/ye+/D6d8ecNzNTQ0Q3Ja4bfeepkSJYrSLY0cUenNc/JEHYBz9WCd53Tm3AVefLs3cyf8RGBAAB/0/YoalSMo/lhBwkIz8HL3T5j2yzAyZzIybF64dJmTp8+xMmojYRky8PLzLe/RTW+ek6fqwBndtOY5hYQEc+PGTXx9fVm0bCof9RrI/n2Hkr8PA7/8mPPnLvDtsFEPnOvSPCegHfA2sBbYYj48trZORAqKyD4RGSsiB0RkkojUE5H1InJQRCqKSIiIjBaRaBHZJiItRMQf6A+0Mx1W2pnHbjCP+VNEinuq3O6kYoWyHD78N3/9dYz4+HimT59L82YNXdI8ffos22J3AYa7y759BwnP45iTi5WoqOgHHF1s852HhAS77BjiiToA1+shITGJuLg7JCQkcut2HNmzZqFEsccIT6GlmDVzJkqWKIqvj3MTWT1VB+7WTcktxvb7EBQU4NT3Id0OcaVUIYdVXacIRq7vV4AY4AWgOtAc+BjYg2Fc8IqIZAKiMQwOPsOm5SQiYUANpVSCmT/8C6CVOwtqdQhRSvHrrxP57XfnM/9ZyROei3+On0x+ffzEKSpWKOuyrpUCBfJSpvRTbIre5jZNgH79etK+fSuuXLlGw4bt0j8hDTxdB+B4PeTMnpVO/3uWem1eJdDfn6oVylKtonvLZIun6sDduhaLhdVRcyhUuAC//zIx2S3mx5GDqd+wFvv3HeLTj750XDe9A0QkUETeF5FZIvKHiLwrIo755jjOX0qpnWaf125ghWlPtRMoCDQAPhSRWIzEc4FA/hR0MgIzRGQXMBx4Mr0L2xocJCWln7XSWYeQh0VISDDTp/3K+z363vPr5g769h1CkSKVmTp1Dl26dHKrtrtxph6uXLvOqqhNLJn2Kytnj+XW7dvMX+qardb/B1JyiwHo2uVDShSpyoH9h2nZ6hmHde25rRuP8U/9A/Cj+XyCw1dyDNt5VEk2r62eeQK0svrQKaXyK6VSskAdAKxSSj0FNMN0ZkkLW4MDiyX95AvOOoSkqXniNPny5kl+nTc8d/J1XMHX15cZ035lypTZzJmzyGW91Jg6dTbPPtvYJQ1P1QE4Xw8bN8cSnjsnWTJlxM/Xl7o1qxC7a1/6JzqJp+rAU7q2bjFWkpKSmDVzAc1bOH7baE9wekop9apSapX5eA07WiAeZgnQTczExiJibZNeA0JtjsuIsdwGPDA3yxWHkLSI2RxLkSKFKFgwH35+frRt24L5C5a6rPvrL0PZu+8Q3373i8ta9/PYYwWTnzdt2oD9+w+7pOepOgDn6yF3zuzs2LOfW7fjUEqxact2ChfI55YypYSn6sCduim5xRw6+BeFCt9N79+oSV0OHHDc6tKeSZhbRaSyUmojgIhUwoMd4nYyAPgW2GHOxfoLaAqs4u7t3pfA18A4EfkUWOjuQrjqEJIaiYmJdH/3UyIXTsbHYmHsuGns2XPAJc1qVSvQsUNrduzcw+YY44vYp89gFi12fMX9+PE/UKNGFbJly8yhQ5sYOHAYDRvWplixx0hKSuLYsRN06/aRS+X1RB2Aa/VQ6oni1K9Vjbad38XHx4fHixamTbOGTJw5nzFTZnH+4iWee/kdalQuT//e3Th/4RLtXn+f6zduYrFYmDhzHnPH/0QGO4fVPVUH7tRNzS1m0dKphIZlQETYtXMvH7zb12Fte6YS7AWKA8fMTfmB/UACoJRSzrv7eTk6ZYpOmQI6ZQo8nJQp9rScGrmxLBqNRmMX9kwlOPpvFESj0WhssadDXKPRaP51dHDSaDReiQ5OGo3GK9HBSaPReCV2ua/8V/EPyOv2yknyUH2H+HtmRdGNO7c9omsR92d6Fg9oAiQmJXlEd2Du2h7R7XPK/UtqLBbPtGPibv/jUlYCjUaj+dfRwUmj0XglOjhpNBqvRAcnjUbjlejgpNFovBIdnFygWLHCxEQvSX6cP7eXbt2cNw6wxR0J6AMC/Fm5ehZRGxawMWYRH5nJ5197oyPbtq/kyvXDZMma2eWy/vrLUE4e307sthUua9nSteurbNu6nNhtK1yq11GjvuGfY9vYumV58rbMmTMRuXASu3etJXLhJDJlyuhSWV2pg9DcWXh+6sd0Xv4Vry4bTMTLRu6jFj925eXIQbwcOYguUcN5OXIQABY/H5oMeZ1XlnzJK4sGkb9yCYevmTFjGFOn/sLOnWvYsWM1lSuVd1gDUq7bL7/4hB3bV7E5ZinTp/1KxoxhTmnr4OQCBw4coULFhlSo2JBKlRtz8+Yt5s5d7LKuxWLh++8G0bRZB0qWrk27ds9SokRRh3Xi4u7Q7JkOVK/SlOpVmlGvXk0iKpRh04YttGjWkaNHj7tcVoDx46fzTNP2btGy8uQTxXn1leepWq0p5SMa0KRJvXtyRjnChAkzaNa84z3bevZ4i5Wr1vPkUzVZuWo9PXu85VJ5XamDpMQkVg6czG/1ejPh2c8p92I9shbNw9yuPzKmySeMafIJ+xfHcGBxDABlnjemIIxu+BFTO3xFnU9fAAenUQwf1p+lS1ZRsuTTlC9fn737nDNNSKluV6xcR9ly9Yio0ICDB484/eP6yAYnGyOESSKyV0RmikiwiNQ1DQ12miYIAebxf4vI1+b2aBEp4s7y1KlTnSNHjnLs2In0D04Hdyagvzf5vC9KKXbs2OOWclpZF7WJi/cZHrjK448XITo6llu3bpOYmMi6tRudzq4ZFbXpAUOGZs0aMHHiTAAmTpxJ8+auGQe4Ugc3zl7mzK6/Abhz4zYXDp0kNGeWe455/JlK7Jm3AYCsRcM5+uduAG5euMrtqzfJXcr+VP9hYaFUr16J0WOmABAfH8+VK1fTOStlUqrb5cvXkphopMTZFL2N8Ly5ndJ+ZIOTSXFghFKqBHAVeB8YC7RTSpXEyLrQxeb4K+b2HzGS1bmNtm2aM236XLdopZSAPo+TTikWi4V1f87n0F/RrFq5Pjn5vLeze89+qlevSJYsmQgKCqRRozrktUkt6yo5cmTj9OmzgOHIkiNHNrdpu0LGvNnI8WQBTsbezSSar2Jxbpy/wqW/zwBwds8xitYvh/hYyJgvO7meKkhYnqx2X6NQofycP3+B338bTkz0Ekb9PITgYM/ka+r0UluWLHFuUuijHpz+UUqtN59PBOpimCNY0/qNA2raHD/F5m8VdxXCz8+Ppk0b8McfbvHpdCtJSUnUqNqMJ4pXM5PPF3vYRbKLffsOMeSbEUQunMyC+RPZvmN38q+xJ/CGlRJ+wQG0/Lk7K/pP5M71W8nbSzSvwl6z1QSwY/oarp26SKf5A6j3WQdObD1IUqL9s9h9fXwoW7Yko0aNp0LFhty4cZNevdK0enSK3r27kZCQyBQnDUUf9eB0/zfqsgPHp/htvMd9JTF99xWARo1qsy12J2fPuscM2RMJ6K9cuca6tRuoV69m+gd7CWPHTqVylSbUrdeay5eucPCg43moU+Ps2fPkypUDMIw2z5274DZtZ7D4+tDy5+7snvMnBxbfzYItPhaKN6rA3vmbkrepxCRWDJjEmCaf8MdrwwkIC+biX6fsvtbxE6c4fvwU0TGGJdYfsxZStkxJ970ZoGPHNjRpXJeXOnVzWuNRD075RcTaAnoBI7d5QZv+pI7AGpvj29n83UAK3OO+4pO++wpAu7YtmDbNPbd04L4E9FmzZSHjPcnnq3PggGvGA/8m2bMbtyr58uXh2WcbM3XqHLdpL1iwjA4dWgPQoUNr5s93j3mCszT5ujMXDp0k5rd73WAKVn+KC4dPcu30XYNt30B//IICkverhCQuHDyJvZw5c47jx09SrNhjgNFfunev67nJrTSoX4sP3n+TVq1f4dYt59dm2pOm15vZD7wtIqMxjDbfATZieNX5Yhhy/mxzfGYR2YFhNfW8OwoQHBxE3bo1eevtD90hB7gvAX2unNn5+ZchWHx8zOTzC1myeBVvdHmJ7u++Rs6c2flz40KWLVlNt66pW4enx8QJP/F0zSpky5aFv49spl//bxgzdqrTelamTf2FrFkzEx+fwDvdP3G603b8+B+pWaMy2bJl4fChaAYMHMqQb35i8qSRvNzpfxw7dpwX2rs2WudKHeSNKMZTrWpwdu+x5OkCa4ZM58iq7TzRrHJyR7iVkGxhtB3fG6WSuH76EvPfG+lwed99rw/jx/2Av78fR/46RufO7zusASnXba+eXfEP8Cdy4WQAoqO30jUNa/rUeGSzEohIQWCB6Ulnz/F/Y7gB233vpbMS6KwEoLMSgM5KoNFoNMk8srd1Sqm/AbtaTebxBT1WGI1G43Z0y0mj0XglOjhpNBqvRAcnjUbjlejgpNFovBIdnDQajVfyyM5z+jfIFlbM7ZVz+bZ9S2IcxVPznG4n3PGIruCZOUmeICHJM2v6fC0+HtE938253ExpkeunWLdrAly/+Zee56TRaB4tdHDSaDReiQ5OGo3GK9HBSaPReCU6OGk0Gq9EBycHCQjwZ+mqmaxeP4+oTQvp/fE7ANSoWZmVa2ezbuMCfvz5K3x8XBuJ8aT7SoECeVmx6g+2bV/JmHHf4+fn55Cupxw3Ro0awrFjW9myZdkD+7p3f43bt4+R1Qm3mJR0+/b9gJiYJWzatIgFCyaSO3dOh3Wt5M2bh+VLZ7Bj+yq2x66kW1dXnGLcWwfBH40i6P1vCXpvGEHvDAHAkqcgQV0HJ2+z5DPMMyR7OEFdBxPy5XT8nm5hl354eG4iF01m85alxGxewltvdbpnf7d3OnP95l9OfW4PPTiJwUMvh73Exd2hZdMXqVWtObWqtaBOvRpUqFiWH3/+itdeeY8alZty/J8T/O+Flk5fw9PuK/0G9GLET2MoW7oOly9f4cWX2jik6ynHjQkTZtC8+YsPbM+bNzf16tXk2DHn3GJS0h02bBQVKjSkUqXGREau4OOPuzulDZCQkEDPXv0oVbo21ao3o0uXTk59XqmVFVyrg1s/9+HW8Pe59X1PAPyfeYk7y6Zza/j73Fk6hYBnzOvdvE7cnN+IX2N/4sSExAQ++mgQEeUbULvWc7z2xos8/riR6zE8PDd169Zw2kzjoQQF0zllv4iMB3YBfUQkRkR2iEg/m+P6mMdFicgUEelhbq9gHhsrIkNEZJeN7joR2Wo+qtpo9UzpGs5wj6OJry+JSYnciY/n8KG/AVi98k+atnDezcPT7is1n67CnNlGxsXJk2bxTNP6Dml6ynEjKir6AV2Ar7/uy8cff+F0nu+UdK9du578PCQk2KUc4qdPn2Vb7C4Arl+/wb59Bwl30pDCU3VwD0ohgYahgQQGk3TVyLKpblwh6fghSEywW+rM6XNsjzWcYK5fv8H+/YfIbb73r77uw6efDna6zA8zZUpR4CUgDGgNVAQEmCciNYFbQCugNOAHbAW2mOeOAV5TSm0QkcE2mmeB+kqp2yJSFMPIIEJEGpjXu+caSqm1zhTcYrGwYu1sChXOz+hfJ7F18w58fXwoU/YpYrftotmzDQkPd+7LCSm7r1SsUNYpLYvFwpqouRQuXIDffpnIX38d48rla8mB5OSJ08lfJnfR6aW2zJg53y1aTZvW5+TJ0+zcudcterb069eT9u1bceXKNRo2bJf+CXZQoEBeypR+ik3R29yiB67WgSLotb4AxG9cQsKmZcTNG01Q58/wb9oJRLj140duKWf+/OGULv0Em2NiecYs8y4XPreHGZyOKqU2isg3QAPA+mlmwAgkocBcpdRt4LaIzAcQkUxAqFLKmrt0MtDUfO4H/CgiZYBEwGo10iCVazgVnJKSkqhdvQVhGUMZP+knHi9RlNdeeY8BX35MQIA/q1ZGkeiAG4YnsbqvZMwYysQpP1OsWGGPXs9Vxw1bgoIC6dWrK02bdnBDyR6kb98h9O07hJ4936ZLl04MGDDMJb2QkGCmT/uV93v0vadl5gqu1sGtnz5GXb2IhGQk8PW+JJ09gW+pKsTNH03izo34lqpKQNu3uf3L5y6VMyQkmElTRtK71wASEhLo0fMtWjR78PbUER5mX491HYcAXyqlypiPIkqp353UfA84g9HaigD8Hb2GrfvK7TtX0rzY1SvXiFq3ibr1arA5OpZmjV6gQe3WbFgfw+FDfzn5FjzrvlKxYjkyZgpN7rDPE56LUy5qW3GH44YthQsXoGDBfMTELGb//vWEh+dm48ZIcubM7hZ9K1OnznbasNOKr68vM6b9ypQps5kzZ1H6J9iJq3WgbG7ZEndtwid/UfzK1yZx50YAEnb8iU8+5/rHrPj6+jJp8kimTZ3LvLlLjDIXyMuGTZHs3ruO8PBcRP05nxw5HfMG9IaO6CXAKyKSAUBEwkUkB7AeaCYigea+pgBKqcvANRGpZJ7/PxutjMAppVQShvOKTzrXeABb95VA/4wP7M+aNTNhNo4mT9euxsGDR8iWzXBo9ff34513X2fcaOcT/HvSfWX//kOGe25L45/xhfbPEblweVoyduEuxw1bdu/eT/785ShevBrFi1fjxIlTVK7chDNnzrmsbWtt3rRpA/bvd82V5tdfhrJ33yG+/e4XF0t2Ly7VgV8ABAQmP/cpVoak08dQVy/hU/hJAHyKlCTpvP22UikxYuRX7N9/iB9/+D25zIUKVuDJEjV4skQNTpw4TfWqzTh7xjHrtIeeplcptVRESgAbzAT114EOSqkYEZkH7MBoDe0ErE2ZV4FfRSQJw/rJun0E8IeIvAgsxmydpXYNjD4qh8iZK4c5VcCCxWJh7uxFLF28ms8H9KJBo9pYLMKY36ewbu1Gp+oDPO++sn/fIUaP/Y5P+7zPjh27GT9uhkO6nnLcGD/+B2rUqEK2bJk5dGgTAwcOY+zYaQ5p2KvbsGFtihV7jKSkJI4dO0G3bs73u1SrWoGOHVqzY+ceNscYPyJ9+gxm0eKVbimrs3UgoZkIfKm38cLiQ8K2dSTu38btuBEEtHgVLBZIiCdu5ojk44PeGYIEBoNS+FVvys1v3oG4W6leo0qVCF5o/xy7du7jz40LAfi87xCWLlntVJnvKb83ZyUQkQxKqesiEozRP/S6Umqrdbt5zIdAbqWU82PBqaCzEuisBKCzEsDDyUrw0FtO6fCLiDwBBALjlFJbze3PiMhHGOU/CnR6SOXTaDQewquDk1LqhVS2TwNcb+9rNBqvxRs6xDUajeYBdHDSaDReiQ5OGo3GK9HBSaPReCU6OGk0Gq/Eq0frHjZ3HFid/bDxVFktHspmE++B8npq5tSTWQp4RHf/ZedSwKRH5u+i3a55uWfV9A9yM7rlpNFovBIdnDQajVeig5NGo/FKdHDSaDReiQ5OGo3GK/nPBCcRWS0iEa7qhIfnZkHkJKI3L2FTzGK6mG4TJUuVYMWqP4jasIDV6+ZSvnwpl67jDvcVgJ9/HsLRo1vYvPluPqhSpZ5gzZrZbNwYSVTUfCIiSrusOWHCj2zcGMnGjZHs2xfFxo2RTpcZICAggA3rF7Bl8zK2x66k72cfuKRnS8aMYUyd+gs7d65hx47VVK5k/yr+fsM/ZtWuhfyxemLytrBMofw87Vvm/TmNn6d9S6iZQ6vJcw2YsXI8M1dNYNz8URR7oki6+p52irHFYrEQE72EObPHOXReUI+fCOo2lMCuQwh8y8iSbclVgMA3BhHUbSgBHXtDQFDy8X41nyXo/R8Ievc7fIrY/117ZIPTw3JtSUhM4JOPv6BiREPq1m7Fa693pPjjRRgw8EMGf/k91as05YuBw+k/8EOnr+Eu9xUw3DxatHjpnm2DBn3EoEHfUblyEwYMGMagQY7lMkpJs2PHrlSu3ITKlZswZ85i5s5d7FR5rcTFxVGvQVvKR9SnfEQDGjaoRaWK5VzStDJ8WH+WLllFyZJPU758ffbuO2j3uXOnRdLl+ffu2fZKt45Er9tC86rtiF63hVe7Gc40J46d5JWWb9O6dkd+GT6Gz77pna6+p51ibHmnW2eH3rstt37/nNs/9uT2CON77t/yTe4smcStHz4gcU80fjWaAyDZ8+JTqhq3vnuP2+MG4d+8M9j5b/tIBacUXFt+F5FdIrJTRNrZHNfb3Lb9PgMERMQiImNFZKAzZUjJbSJPnlwopQgNzQBAWFgop087nMcuGXe6r6xfH83Fi5fv2aaUIizMKGvGjKGcOuVYWVPStKVVq2eYPn2eo0V9AFvnGF8/P7c4j4SFhVK9eiVGj5kCQHx8PFeuXLX7/K0bY7l6+d7jazeswbzpRktx3vRIajeqAcD2zbu4duUaADu27CZn7hSTr96Dp51irISH56Zx47qMHj3FZS0AS7Y8JP29B4DEQzvwfbIyAL4lIkjcsR4SE1CXzpJ08TSWvOm3IOHRnIRpdW0JB97EyBeeDYgRkbVAGaAFUEkpdVNEstic6wtMAnYppQa5WpD8+cMpVfpJNsfE0rvXAGbPHcfALz7CYrFQv05rp3Xd6b6SEj179mf+/PF8+eUnWCwWatd+zm3a1apV5MyZ8xw+/LfLWhaLhehNiynyWEFG/jyW6BjXHU0KFcrP+fMX+P234ZQq9QRbt+7gvfc/4+bN1LM9pkeW7Fk4f/YCAOfPXiBL9iwPHNPyhaZErdzwwHZ7cbdTzNCh/fjoo4FkMH9QHUJB4MufgoKEmGUkxCwn6cw/+JSoQOLeGHyeqoJkzAqAZMxK4rG7WVzVlYtI2IP1kxKPVMvJ5KhSaiNQHZiilEpUSp3BSNdbAagHjFFK3QRQSl20OXcUbgpMISHBTJg8gg97DeDatet07tyej3oP5Ini1fmo90B+HPmVq5fwGK+/3oFevQZQtGgVevXqz8iRX7tNu23b5syY4XqrCQznmIgKDShQKIIKEWV58sniLmv6+vhQtmxJRo0aT4WKDblx4ya9enV1Q2ltuK9lU6FaOVo+34xvB45wWrJv3yEUKVKZqVPn0KVLJ5eK16RJPc6dPc/WbTudOv/2r324/VNvbo8bhG+lhlgKliBu1gj8KjUk8K2vkIBAh7zvUuNRDE6u5Ln9E6gtIqnmtLV1X7mTkHJz39fXl4mTRzB92jzmz1sCwPPtWzHP7GeZPSvSpQ5xT7iv2NK+fatkh5A//ljocId4avj4+NCiRSNmusmzzsqVK1dZvWY9DRvUclnr+IlTHD9+KrkV9seshZQtU9IlzYvnLpIth9FSyJYjKxfPX0reV7TEY/Qd+hHvdurNlUv23z6mhjucYqpWjaBp0wYcPLCRSRNHULt2NcaN/d7u862OLty4SuKeaCx5i6DOn+T22IHcHtGbhO3rSbp4xjj2ygUsZisKQDJmuXt+OjyKwcnKOqCdiPiISHagJhANLANeNvOOc99t3e9AJDBdRFK8pbV1X/H3DUvxwj+NHMz+/Yf56Ye77lKnT52heg3DEObpWlVduq1xl/tKapw6dZYaNYw+gVq1qnHIdCp2lTp1qnPgwGFOnHA9kGbLloWMGY36DwwMpF7dmi47pACcOXOO48dPUqzYY4BR5r17HTePsGX10iiat20CQPO2TVi1ZB0AucJzMmz0l3zStR9Hj/zjtL67nWI+/XQwhQpHULRYZdp3eItVq9bzUqd37DvZLwD8bRxdipRGnfkHQsz/FRH8arciIdr4vibs24xPqWrg44tkzoEla27DVdgOHsU+JyuzgSrAdkABvZRSp4HFpqnmZhG5gxGMkm1AlFLDRCQjMEFE2ps2UnZTuUoEz7/wHLt27SNqwwIA+n/+Dd26fsxXQ/rg6+tL3O04unf9xOk35i73FYBx4763cfPYyIABw3n77d4MGfI5vr4+xMXF0bWrYyOLKWmOGzeNNm2auaUjHCB37pyM/v3bZJebmTPnszDSdQsrgHff68P4cT/g7+/Hkb+O0bnz+3afO3hkPyKqliVTlkws3TqHkUN+Y/QPExjyy0CefaEpp46fpufrnwLwxvsvkylzGB8P7gEYn+sLDV9NU9/TTjGuIhkyEtC+p/Hc4kPCjigSD8biW6UJfpWNQZuE3dEkbFkFgDp7nMRdGwjqPhySkrgz/zew81/Oq91XHjZhIYXdXjk34+PcLQmAn8+j9TvzKGUleOIRy0qQ6AG3GE9lJQgZNCPVj+1Rvq3TaDT/j9HBSaPReCU6OGk0Gq9EByeNRuOV6OCk0Wi8Eh2cNBqNd6KU0g8XH8DrWtczuo9SWR81XW8vq245uYfXta7HdB+lsj5qul5dVh2cNBqNV6KDk0aj8Up0cHIPv2hdj+k+SmV91HS9uqx6bZ1Go/FKdMtJo9F4JTo4aTQar0QHJ41G45Xo4KT5TyAih0Xkzfu2LXhY5dGkz6OVocyLEJEQ4JZSKklEigGPA4uUUvFO6qWZjlEpNcwZXVN7FkaK4kXKwcyfdmiXBmqYL9cppba7Sfc5DBMLBUQppWa7KBmPkT++EvCGUuoOhoOPK2Wcb5YvRZRSzV3ULwx8h5HxNQnYALynlDriom51oKhSaoyZ4jqDUuovFzX7K6U+s3ntA4xXSrV3VlMHJ+dZC9QQkczAUiAGaAc4+2GEuqtgKTACeBn4XkRmYLjT7HdVVES6A68Bs8xNE0XkF6XUDy7qjgCKAFZTtTdEpJ5SynnrY7iplGonIr2AdSLShjQCi5184+L56TEZ+Aloab7+H0adVHJWUET6AhFAcWAM4AdMBKq5VFLIJyIfKaW+FJEAYDrgmpeXJ9bW/BcewFbzbzeM/OUAsQ+7XOmUOSOG198/GE40LwN+LujtAEJsXocAO9xQzn2Y01zM1xZgr4ua22ye1zOvcfZhfybp1W8K27a7qBmLkdF4W1rXcUJXMILpRxg/1u+6qqlbTs4jIlIFo6VkzVrv4wbRQFPvSSDZwkop9YqLulmBDkBHjF+0SRi3TS8BtZyVBWwTVifinlTeh4D8wFHzdT5zmysk33IopZaLSEOM9+4yIlIU+BJ4gns/s8IuSi8SkQ+BqRitvHZApNVRSN3ryWgvd5RSSkSUWfYQVwooIrYe8d9heEOuB9aKSDml1FZntXVwcp53MX4lZiuldpv9A6vcoDsB41e9IdAfI/jtdUVQRGZjNOMnAM2UUqfMXdNEZLML0mOATaY+wLMYfVuuEgrsFZFo83UFDDedeeB0X867IpKolIo0NY6KSF43lBWMeugLDAdqY7RI3THY1Nb8+8Z92/+HEaycCX7TRWQUkElEXgNeAX51vogMve/1JYwgPdQsYx1nhfUMcRcRkWBlugu7SW+bUqqsiOxQSpUSET+MjubKTupZgI+VUgPdVcb79MthtMDAKKfLnuEi8nRa+5VSa5zQPIJxO7tSKdXP3LZVKVUu7TPt0t6ilCovIjuVUiVtt7mq7QlEpD7QAKOVu0QptewhFylF9FQCJxGRKiKyB6OVg4iUNjtyXcU62ndZRJ7C6CfK4ayYMkbnWrmhXA8gIpWBg0qp75VS3wOHzdEwlzCDzz6MFlQoRn/TGuvDSdnLQF0gp4jMN70L3UWc+SNwUES6ikhLIIOroiLiJyLviMhM89HV/LFyCaXUMqVUT6VUD3cFJhH5QkQy2bzOLCIu/SDq4OQ832Lcel0AUMYQek036P5ijgB+CswD9gBfu6i5QkRaiYi7rd1GAtdtXl83t7mEiLTFcG9ug3Frs0lEWrsqq5RKUEq9BfwBROFC0L+P7kAw8A5QHqNv70U36I409UaYj/K4WL8iUllEYkTkuojcEZFEEXHdJx0aK6UuW18opS4BTVxSfFgjEY/6A9hk/t1ms82lkRQPlvUaxjyZO8BV8/VVN+jGprDNHSM/24EcNq+zu1q3GHObbF+XB0a7qX7b2LPNmXqwZ5uDmpsxpmlswxjAeRn40g1l3QEE2LwOAna7oqlbTs7zj4hUBZTZ/O6Bix3X4JnmsVIqVCllUUr5K6XCzNdhrpYVOGLedviZj+6ASxMETSxKqbM2ry/gYitfKTUKQERyiEh+4BzwuSuaNqTkD+4Oz/BEEXnM+sIcdHHZzlcpdQjwUUolKqXGAI1c1cQY/V0hIq+KyKvAMmCcK4J6tM553sQYOg0HTmDM7XBlkqCVxkqpj60vlFKXRKQJxm2eU4jICqVU3fS2OcGbwPdm2RSwAvekaF0sIku4OwmzHRDpiqCINAOGAXmAsxhTFfYCT7mg2Rjj1iVcRL632RUGuMNvvSewyuzMByiI0dJxhZsi4g/EisjXwCnc0L2jlPpKRLZjzCEDGKCUWuKKpg5OTqKUOo/zs8HTwkdEApRScQAiEgQEOCNkzpkKBrKZ/VjWPqcwXFy6AWC2bv7nqk4Kuj1FpBV3Zy3/olxfvjIQqAwsV8ZoaG2MviFXOIlxm9Qc2GKz/RrwnovaYMwXGoXRkX8ZWIKxhMUVOmLcznXFKGM+3Ddgsg1jxrnC1dnh6KkETiMiY0hh+YNyfbJkb6AZxtwZMH4p5ymlHO4UN2+z3sVoLZzgbnC6CvyqlPrRxbJ+jfFPfwtYDJTCWPs10RVdTyAim5VSEeave1llrIncrpQq7QZtP4wf+vzKDcuCbHSnY3xWk8xNLwCZlFJt3HUNd2EOYgwBVmN8z2oAPZVSM53W1MHJOcxfdiuBGOufTiql3nGDdmOMX0uAZa42j0Wkm3JxvVsqurFKqTLm0HlT4H1grav/8GIs+v0KYzRNzIdypZ9MRJZjTBIdDGTFuLWroJSq6kpZTe1mGOvs/JVShUSkDNBfub7wd49S6on0tjmouZMHf1SvYLQAByqlLjipux2ob+0rFGNB8XJXvgv6ts5JlFJ/2L4WkSkYw9Pu0F4ELHKHlqn3g9l5XxCbz1wpNd5FaavWM8AMpdQVN81W+BpjJrvLAww2NAduYwz7d8C4te3nJu3PgYoYrQaUUrEiUsgNultFpLJSaiOAOYfMlRn9YHyvEjHWwYFxWx4MnAbGYrTancHtgxg6OLmPorgwb0ZEopRS1UXkGvf+srmj1TABeAxj0ad1tEcBrganBSKyD+O2rov5a3nbRU2AM+4KTNZ6Bc5wt16tEXSgiFwEhiilXJlAG59CYHbHLUl54E8ROWa+zg/st7Z+lFKlnNCsp+6dFb/TOlNeRJzqgzPnz8W4exBDBycnsQkiYv49DfR2Vs/8B0Ip5YnUKRHAE8rN9/BKqQ/NfqcrSqlEEbkBtHBWz7ydA2Md3TRgDhBnc71ZKZ2XThnTrFcxFkT/iTHJ0Vl2i8gLGIMZRTEmY/7pgp4Vdwzx34+PiFRUSkUDiEgF7i5Yd2qEUSmlRKQixuJq61ImlwcxdJ+Tl2HOazmulIoTkVoYnczjlc3sWyc0ZwDvqLsLfl0tYx2l1EqbYHIPzgQRU3dMGruVq4MNaVw3tyt1IyLBwCcY69XAGFUbYB1x9SbMYDQaY3mNYHS4dwZ2A88opaY7qTsO+FEpFeO2surg5Bhyb4qIB1AupIgw9WMxWjoFMZrFc4EnlVJOLwUQkVVAGYwlIbYtEac6bEXkc6XU5zYjlmL711NBxFsRkQiM4FSQu3cjzt52/SuIubZQKXXFTXr7MGaeHwVuWLe7Ugf6ts5xbFNEPNA3hAspIkySlFIJ5gjYD2ZntqtzRj538fz7uSZGWuFd3A1K4J5+Ftv0tJVNzQ0YyctcSiXrQSYBPTDqw61pkN2N3JcO2uwnuwJsUUrFuiDd0IVzU0QHJwdRStWG5MmRb3E3z/U63LDoFYgXkecxEqFZR05cWomunF/JnxrWFffFMXItzcUIUM0wWmeuklJ62qm4kJ7Ww5xTSs1/2IWwkwjzYS1vU4x1cW+KyAxn5tOBkR/LTeVLRt/WOUkqE+QyKqXapn6WXbpPYCwL2aCUmmIOSbdVSn3lgqbtCKA/RrC74er6OhFZi9FPcc18HQosVEq5lJ1BzFxW921zy4RJTyAidYHnMZbvuNSB72nMz6yJUuq6+ToDsBCj832LK3Oo3I1uOTnPU/d9kKvEyO/kEkqpPRijPZhLTkJdCUymZvJIlTns2wLjlslVcmJkOrByx9zmKp5IT+tJXsZw3/Hj7m2d4q7xgzeRA5sAipE/LKdS6paIeFUHvg5OzuOJCXKIyGqMCYO+GOu1zorIeqVUmtZR9mJOJ5gjhgvHhy7KjQei5d40vWNd1ATPpKf1JBWUUsUfdiHsZBJGfqy55utmwGQxcom7/OPqTvRtnYPYTP/3w+hzOWa+LgDsc7VZLHfT9HYG8iml+qZ0m+Ogpu2QvwWjz+FppVQVV8pqapfjrm/dWuWGNL2PGuao5RCz1ev1mKOL1kXV65VSLv+oegLdcnKcph7W9xWR3Bith0/cpGm7JCEB+BsXJkvaYk6dcGn6hBVPzZ/6F6iMkYLkL4xbJuuUCm+dShCIkWxwjIhkF5FC3jgSqoOTg3hiVOI++mNM4otSSsWYw+oHXRFUSrmaA+jf4mlgJXeDqe1yE2/twwHPzOT2COI5U023o2/r/gOIYYH0A3e/gOuA7kqp4w+vVKkjRh6qVjw4qbH/QyvU/xPMSb5lMUxhy5rbXOo28BS65eRliGdMNcdgzB2y5gHqYG6r74KmJ5mDkVxtK3cXEutfUffgVlNNT6KDk/fhdlNNILsyckVbGSsi77qo6UnyKqUemVulRwVzGskCca+ppsfQBgfeRxGlVB+MSZLjMHIluToz+oKIdBARH/PRAdPSykv5U0RKPuxC/H/DnEbSBpiJYY9VHPhMeSARoTvQLSfv435TzdO47q/2Ckaf03CM26M/gU4uarodm2kavsDLYiT2fxRGvx4ltgKXlVI9H3ZB0kMHJ+/DaqrZB8NUMwNGnhxX6A+8pAyjQ8yZ1t9gBC1vwtPTNDRGK7y9iLgte4Cn0KN1/wGsEzvT26b5/4+IFEhp+78wRcZhdMvJS7g/lcX9KKWGuSBvEZHM97Wc9Gf/H8Qbg1Bq6C+o92BdnGubHwmbba4wFNhgZsQEo1N0kIuaGo1H0bd1XoaZ7rS7NS2v2f801NXskmYqFmsivJWPyjowzX8XHZy8DN0/pNEY6HlO3ofFbC0Bun9I899Ff+m9D90/pNGgb+u8Et0/pNHo4KTRaLwU3eek0Wi8Eh2cNBqNV6KDk+ZfQ0QyichbHtTvJCI/pnPM5yLSw0Hd666VTOMMOjhp/k0yYRiRPoCI6JFjzT3o4KT5NxkMPCYisSIyRERqicg6EZkH7BGRgiKyy3qwiPQQkc/N54+JyGIR2WKe83haFxKRZiKySUS2ichyEbH10ystIhtE5KCZcM16Tk8RiRGRHSLSz71vXeMo+tdK82/yIYYZaRkAEakFlDO3/SUiBdM49xfgTaXUQdMjcAR3p1ukRBRQ2UxJ2xnoBXxg7iuF4ZgSAmwTkYXAU0BRoCLG2sZ5IlJTKbXWmTeqcR0dnDQPm+j0bIlMy+yqwAwj0ywAAeno5gWmmTZb/oDtNeYqpW4Bt0RkFUZAqg40AKy+exkwgpUOTg8JHZw0D5sbNs8TuLerwWrwYMHI3ljGAd0fgGFKqXlmC+1zm333T+6zZoL4Uik1yoFraDyI7nPS/Jtc425qmJQ4A+QQkawiEoCZGVMpdRX4S0TagJGoX0RKp3OtjMAJ8/lL9+1rISKBIpIVqAXEYHgFvmK20hCRcBFxNT2yxgV0y0nzr6GUuiAi681O70XAwvv2x4tIfyAaI7Dss9ndHhgpIp9iGEFOBbancbnPMW4DL2EYdRay2bcDWAVkAwYopU4CJ0WkBMa6RoDrGBZaZ518uxoX0ctXNBqNV6Jv6zQajVeig5NGo/FKdHDSaDReiQ5OGo3GK9HBSaPReCU6OGk0Gq9EByeNRuOV6OCk0Wi8kv8DNRQO64wTARQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "mat = confusion_matrix(y_true, y_pred)\n",
    "sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False,\n",
    "            xticklabels=dict_genres.keys(),\n",
    "            yticklabels=dict_genres.keys())\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4110d958",
   "metadata": {},
   "source": [
    "# cnn-rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c31d0fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Dense, Bidirectional, LSTM, Dropout, Activation, GRU\n",
    "from keras.layers import Conv2D, concatenate, MaxPooling2D, Flatten, Embedding, Lambda\n",
    "\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard, ReduceLROnPlateau\n",
    "from keras import backend as K\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f481ea83",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "num_classes = 10\n",
    "n_features = X_train.shape[2]\n",
    "n_time = X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b2b81efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_filters1=16 \n",
    "nb_filters2=32 \n",
    "nb_filters3=64\n",
    "nb_filters4=64\n",
    "nb_filters5=64\n",
    "ksize = (3,1)\n",
    "pool_size_1= (2,2) \n",
    "pool_size_2= (2,2)\n",
    "pool_size_3 = (2,2)\n",
    "\n",
    "dropout_prob = 0.20\n",
    "dense_size1 = 128\n",
    "lstm_count = 64\n",
    "num_units = 120\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "EPOCH_COUNT = 50\n",
    "L2_regularization = 0.001\n",
    "\n",
    "def conv_recurrent_model_build(model_input):\n",
    "    print('Building model...')\n",
    "    layer = model_input\n",
    "    \n",
    "    ### Convolutional blocks\n",
    "    conv_1 = Conv2D(filters = nb_filters1, kernel_size = ksize, strides=1,\n",
    "                      padding= 'valid', activation='relu', name='conv_1')(layer)\n",
    "    pool_1 = MaxPooling2D(pool_size_1)(conv_1)\n",
    "\n",
    "    conv_2 = Conv2D(filters = nb_filters2, kernel_size = ksize, strides=1,\n",
    "                      padding= 'valid', activation='relu', name='conv_2')(pool_1)\n",
    "    pool_2 = MaxPooling2D(pool_size_1)(conv_2)\n",
    "\n",
    "    conv_3 = Conv2D(filters = nb_filters3, kernel_size = ksize, strides=1,\n",
    "                      padding= 'valid', activation='relu', name='conv_3')(pool_2)\n",
    "    pool_3 = MaxPooling2D(pool_size_1)(conv_3)\n",
    "    \n",
    "    \n",
    "    conv_4 = Conv2D(filters = nb_filters4, kernel_size = ksize, strides=1,\n",
    "                      padding= 'valid', activation='relu', name='conv_4')(pool_3)\n",
    "    pool_4 = MaxPooling2D(pool_size_2)(conv_4)\n",
    "    \n",
    "    \n",
    "    conv_5 = Conv2D(filters = nb_filters5, kernel_size = ksize, strides=1,\n",
    "                      padding= 'valid', activation='relu', name='conv_5')(pool_4)\n",
    "    pool_5 = MaxPooling2D(pool_size_2)(conv_5)\n",
    "\n",
    "    flatten1 = Flatten()(pool_5)\n",
    "    ### Recurrent Block\n",
    "    \n",
    "    # Pooling layer\n",
    "    pool_lstm1 = MaxPooling2D(pool_size_3, name = 'pool_lstm')(layer)\n",
    "    \n",
    "    # Embedding layer\n",
    "\n",
    "    squeezed = Lambda(lambda x: K.squeeze(x, axis= -1))(pool_lstm1)\n",
    "#     flatten2 = K.squeeze(pool_lstm1, axis = -1)\n",
    "#     dense1 = Dense(dense_size1)(flatten)\n",
    "    \n",
    "    # Bidirectional GRU\n",
    "    lstm = Bidirectional(GRU(lstm_count))(squeezed)  #default merge mode is concat\n",
    "    \n",
    "    # Concat Output\n",
    "    concat = concatenate([flatten1, lstm], axis=-1, name ='concat')\n",
    "    \n",
    "    ## Softmax Output\n",
    "    output = Dense(num_classes, activation = 'softmax', name='preds')(concat)\n",
    "    \n",
    "    model_output = output\n",
    "    model = Model(model_input, model_output)\n",
    "    \n",
    "#     opt = Adam(lr=0.001)\n",
    "    opt = RMSprop(lr=0.0005)  # Optimizer\n",
    "    model.compile(\n",
    "            loss='categorical_crossentropy',\n",
    "            optimizer=opt,\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "    \n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "879e02de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    n_frequency = 128\n",
    "    n_frames = 130\n",
    "    #reshape and expand dims for conv2d\n",
    "#     x_train = x_train.reshape(-1, n_frequency, n_frames)\n",
    "#     X_train = np.expand_dims(X_train, axis = -1)\n",
    "    \n",
    "#     x_val = x_val.reshape(-1, n_frequency, n_frames)\n",
    "#     X_test = np.expand_dims(X_test, axis = -1)\n",
    "    \n",
    "    \n",
    "    input_shape = (n_frames, n_frequency, 1)\n",
    "    model_input = Input(input_shape, name='input')\n",
    "    \n",
    "    model = conv_recurrent_model_build(model_input)\n",
    "    \n",
    "#     tb_callback = TensorBoard(log_dir='./logs/4', histogram_freq=1, batch_size=32, write_graph=True, write_grads=False,\n",
    "#                               write_images=False, embeddings_freq=0, embeddings_layer_names=None,\n",
    "#                               embeddings_metadata=None)\n",
    "    checkpoint_callback = ModelCheckpoint('./models/parallel/weights.best.h5', monitor='val_accuracy', verbose=1,\n",
    "                                          save_best_only=True, mode='max')\n",
    "    \n",
    "    reducelr_callback = ReduceLROnPlateau(\n",
    "                monitor='val_accuracy', factor=0.5, patience=10, min_delta=0.01,\n",
    "                verbose=1\n",
    "            )\n",
    "    callbacks_list = [checkpoint_callback, reducelr_callback]\n",
    "\n",
    "    # Fit the model and get training history.\n",
    "    print('Training...')\n",
    "    history = model.fit(X_train, y_train, batch_size=BATCH_SIZE, epochs=EPOCH_COUNT,\n",
    "                        validation_data=(X_test, y_test), verbose=1, callbacks=callbacks_list)\n",
    "\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b24a80bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_summary_stats(history):\n",
    "    # List all data in history\n",
    "    print(history.history.keys())\n",
    "\n",
    "    # Summarize history for accuracy\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    # Summarize history for loss\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "990b948d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model...\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input (InputLayer)             [(None, 130, 128, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv_1 (Conv2D)                (None, 128, 128, 16  64          ['input[0][0]']                  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_26 (MaxPooling2D  (None, 64, 64, 16)  0           ['conv_1[0][0]']                 \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv_2 (Conv2D)                (None, 62, 64, 32)   1568        ['max_pooling2d_26[0][0]']       \n",
      "                                                                                                  \n",
      " max_pooling2d_27 (MaxPooling2D  (None, 31, 32, 32)  0           ['conv_2[0][0]']                 \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv_3 (Conv2D)                (None, 29, 32, 64)   6208        ['max_pooling2d_27[0][0]']       \n",
      "                                                                                                  \n",
      " max_pooling2d_28 (MaxPooling2D  (None, 14, 16, 64)  0           ['conv_3[0][0]']                 \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv_4 (Conv2D)                (None, 12, 16, 64)   12352       ['max_pooling2d_28[0][0]']       \n",
      "                                                                                                  \n",
      " max_pooling2d_29 (MaxPooling2D  (None, 6, 8, 64)    0           ['conv_4[0][0]']                 \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv_5 (Conv2D)                (None, 4, 8, 64)     12352       ['max_pooling2d_29[0][0]']       \n",
      "                                                                                                  \n",
      " pool_lstm (MaxPooling2D)       (None, 65, 64, 1)    0           ['input[0][0]']                  \n",
      "                                                                                                  \n",
      " max_pooling2d_30 (MaxPooling2D  (None, 2, 4, 64)    0           ['conv_5[0][0]']                 \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " lambda_2 (Lambda)              (None, 65, 64)       0           ['pool_lstm[0][0]']              \n",
      "                                                                                                  \n",
      " flatten_4 (Flatten)            (None, 512)          0           ['max_pooling2d_30[0][0]']       \n",
      "                                                                                                  \n",
      " bidirectional_1 (Bidirectional  (None, 128)         49920       ['lambda_2[0][0]']               \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " concat (Concatenate)           (None, 640)          0           ['flatten_4[0][0]',              \n",
      "                                                                  'bidirectional_1[0][0]']        \n",
      "                                                                                                  \n",
      " preds (Dense)                  (None, 10)           6410        ['concat[0][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 88,874\n",
      "Trainable params: 88,874\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Training...\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\User\\anaconda3\\envs\\python_course\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\User\\anaconda3\\envs\\python_course\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\User\\anaconda3\\envs\\python_course\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\User\\anaconda3\\envs\\python_course\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\User\\anaconda3\\envs\\python_course\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\User\\anaconda3\\envs\\python_course\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"model_3\" is incompatible with the layer: expected shape=(None, 130, 128, 1), found shape=(64, 128, 130, 1)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [65]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model, history  \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [63]\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(X_train, y_train, X_test, y_test)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Fit the model and get training history.\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 32\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCH_COUNT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model, history\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\python_course\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file9pv07bnc.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\User\\anaconda3\\envs\\python_course\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\User\\anaconda3\\envs\\python_course\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\User\\anaconda3\\envs\\python_course\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\User\\anaconda3\\envs\\python_course\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\User\\anaconda3\\envs\\python_course\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\User\\anaconda3\\envs\\python_course\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"model_3\" is incompatible with the layer: expected shape=(None, 130, 128, 1), found shape=(64, 128, 130, 1)\n"
     ]
    }
   ],
   "source": [
    "model, history  = train_model(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0742263f",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_summary_stats(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27396592",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_true = np.argmax(y_test, axis = 1)\n",
    "X_test = np.expand_dims(X_test, axis = -1)\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "labels = [1,2,3,4,5,6,7,8,9,10]\n",
    "target_names = dict_genres.keys()\n",
    "\n",
    "print(y_true.shape, y_pred.shape)\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcff68a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "mat = confusion_matrix(y_true, y_pred)\n",
    "sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False,\n",
    "            xticklabels=dict_genres.keys(),\n",
    "            yticklabels=dict_genres.keys())\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
